name: DevSecOps Agentic AI Pipeline (BugBuster)

on:
  push:
    branches: [feature/devsecops-agent-bgbstr]
  workflow_dispatch:

concurrency:
  group: devsecops-${{ github.ref }}
  cancel-in-progress: true

# ðŸ”§ Recommended for AutoFix + PR job
permissions:
  contents: write
  pull-requests: write

env:
  JAVA_VERSION: "17"
  PYTHON_VERSION: "3.12"
  APP_DIR: "java-pilot-app"
  REPORTS_DIR: "reports"
  MIN_SEVERITY: "low"
  LLM_ENABLED: "true"
  LLM_EXPLAIN: "0"
  LLM_MODE: "openai"
  BASE_BRANCH: "feature/devsecops-agent-bgbstr"
  SEVERITY_MODE: "threshold"

jobs:

# ============================================================
# ðŸ” VAULT CONNECTION VALIDATION
# ============================================================
  Vault-Connection-Check:
    runs-on: ubuntu-latest
    steps:
      - name: Validate Vault Connectivity
        run: |
          set -euxo pipefail
          echo "ðŸ” Testing connectivity to HashiCorp Vault..."
          VAULT_URL="${{ secrets.VAULT_ADDR }}/v1/sys/health"
          echo "Vault Health Endpoint: $VAULT_URL"

          HTTP_CODE=$(curl -s -o /tmp/vault_health.json -w "%{http_code}" \
            --connect-timeout 10 --max-time 15 "$VAULT_URL" || echo "000")

          echo "HTTP Status Code: $HTTP_CODE"
          cat /tmp/vault_health.json || true

          if [ "$HTTP_CODE" = "000" ]; then
            echo "âŒ FAILED: Cannot reach Vault server. Check EC2 Security Group (port 8200) and VAULT_ADDR secret."
            exit 1
          elif [ "$HTTP_CODE" = "200" ]; then
            echo "âœ… Vault is reachable, initialized, and unsealed."
          elif [ "$HTTP_CODE" = "429" ]; then
            echo "âš ï¸ Vault is reachable but in standby mode."
          elif [ "$HTTP_CODE" = "472" ]; then
            echo "âš ï¸ Vault is reachable but in recovery mode."
          elif [ "$HTTP_CODE" = "501" ]; then
            echo "âŒ FAILED: Vault is reachable but NOT initialized."
            exit 1
          elif [ "$HTTP_CODE" = "503" ]; then
            echo "âŒ FAILED: Vault is reachable but SEALED. Run 'vault operator unseal' on EC2."
            exit 1
          else
            echo "âš ï¸ Unexpected status code: $HTTP_CODE"
            exit 1
          fi

      - name: Validate Vault Secret Fetch (AppRole Auth)
        id: vault_check
        uses: hashicorp/vault-action@v3
        with:
          url: ${{ secrets.VAULT_ADDR }}
          method: approle
          roleId: ${{ secrets.VAULT_ROLE_ID }}
          secretId: ${{ secrets.VAULT_SECRET_ID }}
          secrets: |
            secret/data/openai api_key | OPENAI_API_KEY

      - name: Confirm Secret Retrieved
        run: |
          set -euxo pipefail
          if [ -z "${{ steps.vault_check.outputs.OPENAI_API_KEY }}" ]; then
            echo "âŒ FAILED: OPENAI_API_KEY was NOT fetched from Vault."
            exit 1
          else
            MASKED_KEY=$(echo "${{ steps.vault_check.outputs.OPENAI_API_KEY }}" | cut -c1-7)
            echo "âœ… SUCCESS: OPENAI_API_KEY fetched from Vault (starts with: ${MASKED_KEY}...)"
            echo "ðŸ” Secret is available for downstream jobs."
          fi

# ============================================================
# BUILD APP
# ============================================================
  Build-Java-App:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: ${{ env.JAVA_VERSION }}
          cache: maven

      - run: mvn -B clean package -DskipTests -f $APP_DIR/pom.xml

      - name: Show target
        run: ls -la "$APP_DIR/target"

      # Upload the entire target/ so we can reuse compiled classes & the JAR
      - uses: actions/upload-artifact@v4
        with:
          name: app-target
          path: ${{ env.APP_DIR }}/target/

# ============================================================
# SAST
# ============================================================
  SAST-Scanning:
    runs-on: ubuntu-latest
    needs: Build-Java-App
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: ${{ env.JAVA_VERSION }}

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - run: mkdir -p $REPORTS_DIR

      # Reuse compiled classes (no rebuild) from the same run
      - uses: actions/download-artifact@v4
        with:
          name: app-target
          path: ${{ env.APP_DIR }}/target/

      # Semgrep on source (no rebuild)
      - name: Semgrep (Java + OWASP Top 10)
        run: |
          set -euxo pipefail
          pip install semgrep
          semgrep scan \
            --config=p/java \
            --config=p/owasp-top-ten \
            --json \
            --output "$REPORTS_DIR/semgrep.json" \
            "$APP_DIR/src/main/java" || echo '{}' > "$REPORTS_DIR/semgrep.json"

      # SpotBugs on compiled classes already present in target/
      - name: SpotBugs XML
        run: |
          set -euxo pipefail
          mvn -q -DskipTests -f $APP_DIR/pom.xml spotbugs:spotbugs || true
          if [ -f "$APP_DIR/target/spotbugsXml.xml" ]; then
            cp "$APP_DIR/target/spotbugsXml.xml" reports/spotbugs.xml
          else
            echo "<BugCollection/>" > reports/spotbugs.xml
          fi

      - name: Convert SpotBugs XML â†’ JSON
        run: |
          set -euxo pipefail
          pip install xmltodict
          python - << 'PY'
          import xmltodict, json, pathlib
          p = pathlib.Path("reports/spotbugs.xml")
          out = pathlib.Path("reports/spotbugs.json")
          if p.exists() and p.stat().st_size > 0:
              try:
                  data = xmltodict.parse(p.read_text())
              except Exception:
                  data = {}
              out.write_text(json.dumps(data, indent=2))
          else:
              out.write_text("{}")
          PY

      # Per-stage summary (uses your local composite action)
      - name: SAST Stage Summary
        uses: ./.github/actions/stage-summary
        with:
          stage: SAST
          reports_dir: reports
          files: semgrep.json,spotbugs.json

      - uses: actions/upload-artifact@v4
        with:
          name: sast-reports
          path: reports/*.json
          if-no-files-found: ignore

# ============================================================
# SECRETS
# ============================================================
  Secrets-Scanning:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - run: mkdir -p $REPORTS_DIR

      - name: Install jq
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Install gitleaks
        run: |
          set -euxo pipefail
          VERSION=$(curl -s https://api.github.com/repos/gitleaks/gitleaks/releases/latest | jq -r .tag_name || true)
          if [ -z "$VERSION" ] || [ "$VERSION" = "null" ]; then
            VERSION="v8.18.4"   # fallback pin
          fi
          curl -L -o gitleaks.tar.gz "https://github.com/gitleaks/gitleaks/releases/download/${VERSION}/gitleaks_${VERSION#v}_linux_x64.tar.gz"
          tar -xzf gitleaks.tar.gz
          sudo mv gitleaks /usr/local/bin/

      - name: Run gitleaks
        run: |
          set -euxo pipefail
          gitleaks detect --no-git --source "." --report-format json \
            --exit-code 0 --redact --log-level=info \
            --report-path "$REPORTS_DIR/gitleaks.json" || echo '{}' > "$REPORTS_DIR/gitleaks.json"

      - name: Secrets Stage Summary
        uses: ./.github/actions/stage-summary
        with:
          stage: Secrets
          reports_dir: reports
          files: gitleaks.json

      - uses: actions/upload-artifact@v4
        with:
          name: secrets-reports
          path: reports/*.json
          if-no-files-found: ignore

# =========================================================
# SCA (Trivy FS)
# =========================================================
  SCA-Scanning:
    runs-on: ubuntu-latest
    continue-on-error: true
    env:
      TRIVY_VERSION: "0.51.2"
      REPORTS_DIR: reports
      APP_DIR: .
    steps:
      - uses: actions/checkout@v4

      - name: Prepare reports folder
        run: |
          set -euxo pipefail
          mkdir -p "$REPORTS_DIR"

      - name: Install Trivy (pinned, resilient)
        run: |
          set -euxo pipefail
          TRIVY_VERSION="${TRIVY_VERSION:-0.51.2}"

          # Detect arch and candidate archive names across older/newer releases
          ARCH="$(uname -m)"
          case "$ARCH" in
            x86_64)  CAND_ARCHES=("Linux-64bit" "Linux-AMD64" "linux_amd64");;
            aarch64) CAND_ARCHES=("Linux-ARM64" "linux_arm64");;
            *) echo "Unsupported arch: $ARCH"; exit 1;;
          esac

          BASE="https://github.com/aquasecurity/trivy/releases/download/v${TRIVY_VERSION}"

          downloaded=""
          # Try tarballs with several naming patterns
          for A in "${CAND_ARCHES[@]}"; do
            for ext in tar.gz tgz; do
              URL="${BASE}/trivy_${TRIVY_VERSION}_${A}.${ext}"
              echo "Trying ${URL}"
              if curl -sSfL "${URL}" -o /tmp/trivy.tgz; then
                tar -xzf /tmp/trivy.tgz -C /tmp trivy
                sudo install /tmp/trivy /usr/local/bin/trivy
                downloaded="ok"
                break 2
              fi
            done
          done

          # Fallback: DEB package on Ubuntu runners
          if [ -z "${downloaded}" ] && command -v dpkg >/dev/null 2>&1; then
            for A in "${CAND_ARCHES[@]}"; do
              DEB="${BASE}/trivy_${TRIVY_VERSION}_${A}.deb"
              echo "Trying ${DEB}"
              if curl -sSfL "${DEB}" -o /tmp/trivy.deb; then
                sudo dpkg -i /tmp/trivy.deb || sudo apt-get -y -f install
                downloaded="ok"
                break
              fi
            done
          fi

          if [ -z "${downloaded}" ]; then
            echo "Could not fetch a Trivy binary for v${TRIVY_VERSION}. Will use Docker image at runtime."
            echo "USE_TRIVY_DOCKER=true" >> "$GITHUB_ENV"
          else
            which trivy
            trivy --version
          fi

      - name: Trivy FS (SCA) scan
        run: |
          set -euxo pipefail
          : > "$REPORTS_DIR/trivy_fs.json"
          if [ "${USE_TRIVY_DOCKER:-}" = "true" ]; then
            # Prefer versioned tag; fallback to latest if pull fails
            TRIVY_IMG="aquasec/trivy:${TRIVY_VERSION}"
            docker pull "$TRIVY_IMG" || { TRIVY_IMG="aquasec/trivy:latest"; docker pull "$TRIVY_IMG"; }
            docker run --rm \
              -v "$PWD":/workspace \
              "$TRIVY_IMG" fs \
              --format json \
              --timeout 10m \
              --output /workspace/$REPORTS_DIR/trivy_fs.json \
              /workspace || true
          else
            trivy fs \
              --format json \
              --output "$REPORTS_DIR/trivy_fs.json" \
              --timeout 10m \
              "$APP_DIR" || true
          fi
          if [ ! -s "$REPORTS_DIR/trivy_fs.json" ]; then
            echo '{}' > "$REPORTS_DIR/trivy_fs.json"
          fi

      - name: SCA Stage Summary
        uses: ./.github/actions/stage-summary
        with:
          stage: SCA
          reports_dir: reports
          files: trivy_fs.json

      - name: Upload SCA reports
        uses: actions/upload-artifact@v4
        with:
          name: sca-reports
          path: reports/*.json
          if-no-files-found: ignore

# ============================================================
# IAC (Checkov: Terraform & Kubernetes)
# ============================================================
  IAC-Scanning:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - name: Prepare reports folder
        run: mkdir -p "$REPORTS_DIR"

      - name: Install Checkov
        run: pip install checkov

      - name: Checkov (Terraform JSON)
        run: |
          set -euxo pipefail
          : > "$REPORTS_DIR/checkov_tf.json"
          if [ -d "$APP_DIR/terraform" ]; then
            checkov -d "$APP_DIR/terraform" --framework terraform -o json > "$REPORTS_DIR/checkov_tf.json" || true
          else
            echo '{}' > "$REPORTS_DIR/checkov_tf.json"
          fi
          if [ ! -s "$REPORTS_DIR/checkov_tf.json" ]; then echo '{}' > "$REPORTS_DIR/checkov_tf.json"; fi

      - name: Checkov (Kubernetes JSON)
        run: |
          set -euxo pipefail
          : > "$REPORTS_DIR/checkov_k8s.json"
          if [ -d "$APP_DIR/k8s" ]; then
            checkov -d "$APP_DIR/k8s" --framework kubernetes -o json > "$REPORTS_DIR/checkov_k8s.json" || true
          else
            echo '{}' > "$REPORTS_DIR/checkov_k8s.json"
          fi
          if [ ! -s "$REPORTS_DIR/checkov_k8s.json" ]; then echo '{}' > "$REPORTS_DIR/checkov_k8s.json"; fi

      - name: IaC Stage Summary
        uses: ./.github/actions/stage-summary
        with:
          stage: IaC
          reports_dir: reports
          files: checkov_tf.json,checkov_k8s.json

      - uses: actions/upload-artifact@v4
        with:
          name: iac-reports
          path: reports/*.json
          if-no-files-found: ignore

# ============================================================
# CONTAINER (Trivy Image)
# ============================================================
  Container-Scanning:
    runs-on: ubuntu-latest
    needs: Build-Java-App
    continue-on-error: true
    env:
      TRIVY_VERSION: "0.51.2"
      REPORTS_DIR: reports
      APP_DIR: .
      IMAGE_NAME: java-pilot-app:1.0.0
    steps:
      - uses: actions/checkout@v4

      # Download the jar produced by Build-Java-App
      - uses: actions/download-artifact@v4
        with:
          name: app-target
          path: ${{ env.APP_DIR }}/target/

      - name: Verify jar
        run: |
          set -euxo pipefail
          echo "Listing target folder:"
          ls -la "$APP_DIR/target"
          if [ ! -f "$APP_DIR/target/java-pilot-app-1.0.0.jar" ]; then
            echo "âŒ JAR missing at $APP_DIR/target/java-pilot-app-1.0.0.jar"
            exit 1
          fi

      - name: Prepare reports folder
        run: |
          set -euxo pipefail
          mkdir -p "$REPORTS_DIR"

      - name: Build Docker image (build from app folder)
        id: buildimg
        working-directory: ${{ env.APP_DIR }}
        run: |
          set -euxo pipefail
          if docker build -t "$IMAGE_NAME" -f "$APP_DIR/Dockerfile" . ; then
            echo "built=true" >> "$GITHUB_OUTPUT"
          else
            echo "built=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Install Trivy (pinned, resilient)
        run: |
          set -euxo pipefail
          TRIVY_VERSION="${TRIVY_VERSION:-0.51.2}"

          ARCH="$(uname -m)"
          case "$ARCH" in
            x86_64)  CAND_ARCHES=("Linux-64bit" "Linux-AMD64" "linux_amd64");;
            aarch64) CAND_ARCHES=("Linux-ARM64" "linux_arm64");;
            *) echo "Unsupported arch: $ARCH"; exit 1;;
          esac

          BASE="https://github.com/aquasecurity/trivy/releases/download/v${TRIVY_VERSION}"

          downloaded=""
          for A in "${CAND_ARCHES[@]}"; do
            for ext in tar.gz tgz; do
              URL="${BASE}/trivy_${TRIVY_VERSION}_${A}.${ext}"
              echo "Trying ${URL}"
              if curl -sSfL "${URL}" -o /tmp/trivy.tgz; then
                tar -xzf /tmp/trivy.tgz -C /tmp trivy
                sudo install /tmp/trivy /usr/local/bin/trivy
                downloaded="ok"
                break 2
              fi
            done
          done

          if [ -z "${downloaded}" ] && command -v dpkg >/dev/null 2>&1; then
            for A in "${CAND_ARCHES[@]}"; do
              DEB="${BASE}/trivy_${TRIVY_VERSION}_${A}.deb"
              echo "Trying ${DEB}"
              if curl -sSfL "${DEB}" -o /tmp/trivy.deb; then
                sudo dpkg -i /tmp/trivy.deb || sudo apt-get -y -f install
                downloaded="ok"
                break
              fi
            done
          fi

          if [ -z "${downloaded}" ]; then
            echo "Could not fetch a Trivy binary for v${TRIVY_VERSION}. Will use Docker image at runtime."
            echo "USE_TRIVY_DOCKER=true" >> "$GITHUB_ENV"
          else
            which trivy
            trivy --version
          fi

      - name: Trivy Image Scan (only if image built)
        if: steps.buildimg.outputs.built == 'true'
        run: |
          set -euxo pipefail
          : > "$REPORTS_DIR/trivy_image.json"
          if [ "${USE_TRIVY_DOCKER:-}" = "true" ]; then
            TRIVY_IMG="aquasec/trivy:${TRIVY_VERSION}"
            docker pull "$TRIVY_IMG" || { TRIVY_IMG="aquasec/trivy:latest"; docker pull "$TRIVY_IMG"; }
            docker run --rm \
              -v /var/run/docker.sock:/var/run/docker.sock \
              -v "$PWD/$REPORTS_DIR":/reports \
              "$TRIVY_IMG" image \
              --format json \
              --timeout 10m \
              --output /reports/trivy_image.json \
              "$IMAGE_NAME" || true
          else
            trivy image \
              --format json \
              --timeout 10m \
              --output "$REPORTS_DIR/trivy_image.json" \
              "$IMAGE_NAME" || true
          fi
          if [ ! -s "$REPORTS_DIR/trivy_image.json" ]; then
            echo '{}' > "$REPORTS_DIR/trivy_image.json"
          fi

      - name: Trivy Image Scan (fallback when build failed)
        if: steps.buildimg.outputs.built != 'true'
        run: |
          set -euxo pipefail
          echo '{}' > "$REPORTS_DIR/trivy_image.json"

      - name: Container Stage Summary
        uses: ./.github/actions/stage-summary
        with:
          stage: Container
          reports_dir: reports
          files: trivy_image.json

      - name: Upload container reports
        uses: actions/upload-artifact@v4
        with:
          name: container-reports
          path: reports/*.json
          if-no-files-found: ignore

# ============================================================
# DAST
# ============================================================
  DAST-Scanning:
    runs-on: ubuntu-latest
    needs: Build-Java-App
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: app-target
          path: ${{ env.APP_DIR }}/target/

      - run: mkdir -p $REPORTS_DIR

      - name: Start Application
        run: |
          set -euxo pipefail
          mkdir -p config/dummy
          java -jar "$APP_DIR/target/java-pilot-app-1.0.0.jar" \
            --spring.config.import=optional:file:./config/*/ &
          sleep 40

      - name: OWASP ZAP Baseline
        run: |
          set -euxo pipefail
          mkdir -p zap-output
          docker run --rm \
            -u root \
            --network=host \
            -v "$(pwd)/zap-output":/zap/wrk:rw \
            ghcr.io/zaproxy/zaproxy:stable \
            zap-baseline.py \
            -t http://localhost:8080 \
            -J zap.json || true
          if [ -f zap-output/zap.json ]; then
            mv zap-output/zap.json "$REPORTS_DIR/zap.json"
          else
            echo '{}' > "$REPORTS_DIR/zap.json"
          fi

      - name: DAST Stage Summary
        uses: ./.github/actions/stage-summary
        with:
          stage: DAST
          reports_dir: reports
          files: zap.json

      - uses: actions/upload-artifact@v4
        with:
          name: dast-reports
          path: reports/*.json
          if-no-files-found: ignore

# ============================================================
# AGGREGATE
# ============================================================
  Aggregate-Scanning-Reports:
    runs-on: ubuntu-latest
    needs: [SAST-Scanning, Secrets-Scanning, SCA-Scanning, IAC-Scanning, Container-Scanning, DAST-Scanning]
    if: always()
    outputs:
      decision: ${{ steps.aggr.outputs.decision }}
      critical: ${{ steps.aggr.outputs.critical }}
      high:     ${{ steps.aggr.outputs.high }}
      medium:   ${{ steps.aggr.outputs.medium }}
      low:      ${{ steps.aggr.outputs.low }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          path: collected-reports

      - name: Collate JSON
        run: |
          set -euxo pipefail
          mkdir -p final-reports
          find collected-reports -name "*.json" -exec cp {} final-reports/ \; || true
          echo "DEBUG: Aggregated files"
          ls -la final-reports || true

      - name: Aggregate & Decide
        id: aggr
        uses: ./.github/actions/severity-aggregate
        with:
          reports_dir: final-reports
          output_dir: final-reports
          min_severity: ${{ env.MIN_SEVERITY }}

      - name: Print decision and totals (debug)
        run: |
          echo "Decision: ${{steps.aggr.outputs.decision}}"
          echo "Critical: ${{steps.aggr.outputs.critical}}"
          echo "High: ${{steps.aggr.outputs.high}}"
          echo "Medium: ${{steps.aggr.outputs.medium}}"
          echo "Low: ${{steps.aggr.outputs.low}}"

      - name: Append decision to Job Summary
        run: |
          {
            echo "### Aggregate Decision"
            echo ""
            echo "- **Threshold (MIN_SEVERITY)**: \`${{ env.MIN_SEVERITY }}\`"
            echo "- **Decision**: \`${{ steps.aggr.outputs.decision }}\`"
            echo ""
            echo "| Severity | Count |"
            echo "|----------|------:|"
            echo "| CRITICAL | ${{ steps.aggr.outputs.critical }} |"
            echo "| HIGH     | ${{ steps.aggr.outputs.high }} |"
            echo "| MEDIUM   | ${{ steps.aggr.outputs.medium }} |"
            echo "| LOW      | ${{ steps.aggr.outputs.low }} |"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Show overall_summary.json
        run: |
          if command -v jq >/dev/null 2>&1; then
            jq . final-reports/overall_summary.json || cat final-reports/overall_summary.json
          else
            cat final-reports/overall_summary.json
          fi

      - uses: actions/upload-artifact@v4
        with:
          name: overall-summary
          path: |
            final-reports/overall_summary.json
            final-reports/overall_summary.md

      - uses: actions/upload-artifact@v4
        with:
          name: all-scan-reports
          path: final-reports/*.json

# ============================================================
# AI Analysis
# ============================================================
  AI-Security-Intelligence:
    runs-on: ubuntu-latest
    needs: Aggregate-Scanning-Reports
    if: always()
    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: all-scan-reports
          path: final-reports

      - uses: actions/setup-python@v5
        with:
          python-version: 3.12

      # ðŸ” Fetch OpenAI API Key from Vault
      - name: Import Secrets from HashiCorp Vault
        id: vault
        uses: hashicorp/vault-action@v3
        with:
          url: ${{ secrets.VAULT_ADDR }}
          method: approle
          roleId: ${{ secrets.VAULT_ROLE_ID }}
          secretId: ${{ secrets.VAULT_SECRET_ID }}
          secrets: |
            secret/data/openai api_key | OPENAI_API_KEY

      - name: Install dependencies
        run: pip install openai

      # âœ… Validate secret before running
      - name: Validate OpenAI Key
        run: |
          if [ -z "${OPENAI_API_KEY}" ]; then
            echo "âŒ OPENAI_API_KEY missing"
            exit 1
          fi
          echo "OPENAI_API_KEY prefix: ${OPENAI_API_KEY:0:7}******"
        env:
          OPENAI_API_KEY: ${{ steps.vault.outputs.OPENAI_API_KEY }}

      - name: Run AI Security Intelligence Agent
        run: python tools/agent/security_intelligence_agent.py
        env:
          OPENAI_API_KEY: ${{ steps.vault.outputs.OPENAI_API_KEY }}
          LLM_ENABLED: "true"
          MIN_SEVERITY: ${{ env.MIN_SEVERITY }}

      - uses: actions/upload-artifact@v4
        with:
          name: ai-security-intelligence
          path: agent_output/*

# ============================================================
# AI GATE
# ============================================================
  Severity-Gate:
    runs-on: ubuntu-latest
    needs: Aggregate-Scanning-Reports
    outputs:
      gate_failed: ${{ steps.set.outputs.gate_failed }}
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: overall-summary
          path: final-report

      - name: Decide from Aggregate
        id: set
        run: |
          ls -la final-report/* || true
          cat final-report/overall_summary.json || true
          echo "Decision: ${{ needs.Aggregate-Scanning-Reports.outputs.decision }}"
          if [ "${{ needs.Aggregate-Scanning-Reports.outputs.decision }}" = "FAIL" ]; then
            echo "gate_failed=true" >> $GITHUB_OUTPUT
          else
            echo "gate_failed=false" >> $GITHUB_OUTPUT
          fi

# ============================================================
#  Build the FAISS index (RAG)
# ============================================================
  Build-Repo-Index:
    runs-on: ubuntu-latest
    needs: [Aggregate-Scanning-Reports, Vault-Connection-Check]
    if: needs.Aggregate-Scanning-Reports.outputs.decision == 'FAIL'
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      # ðŸ” Fetch OpenAI API Key from Vault
      - name: Import Secrets from HashiCorp Vault
        id: vault
        uses: hashicorp/vault-action@v3
        with:
          url: ${{ secrets.VAULT_ADDR }}
          method: approle
          roleId: ${{ secrets.VAULT_ROLE_ID }}
          secretId: ${{ secrets.VAULT_SECRET_ID }}
          secrets: |
            secret/data/openai api_key | OPENAI_API_KEY

      - name: Install dependencies
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip
          pip install --no-cache-dir openai faiss-cpu pyyaml

      - name: Validate OpenAI Key
        run: |
          if [ -z "${OPENAI_API_KEY}" ]; then
            echo "âŒ OPENAI_API_KEY missing"
            exit 1
          fi
          echo "OPENAI_API_KEY prefix: ${OPENAI_API_KEY:0:7}******"
        env:
          OPENAI_API_KEY: ${{ steps.vault.outputs.OPENAI_API_KEY }}

      - name: Build FAISS index
        run: python tools/embeddings/build_index.py
        env:
          OPENAI_API_KEY: ${{ steps.vault.outputs.OPENAI_API_KEY }}
          PYTHONPATH: tools

      - uses: actions/upload-artifact@v4
        with:
          name: rag-index
          path: agent_output/index

# ============================================================
#  Agentic AI (LangChain/RAG) Autofix
# ============================================================
  Agentic-AI-Autofix:
    runs-on: ubuntu-latest
    needs: [Aggregate-Scanning-Reports, Build-Repo-Index, Vault-Connection-Check]
    if: needs.Aggregate-Scanning-Reports.outputs.decision == 'FAIL'
    env:
      RAG_DEBUG: "true"
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      # Download FAISS index
      - uses: actions/download-artifact@v4
        with:
          name: rag-index
          path: agent_output/index

      # Download aggregated scan reports
      - uses: actions/download-artifact@v4
        with:
          name: all-scan-reports
          path: final-reports

      # ðŸ” Fetch OpenAI API Key from Vault
      - name: Import Secrets from HashiCorp Vault
        id: vault
        uses: hashicorp/vault-action@v3
        with:
          url: ${{ secrets.VAULT_ADDR }}
          method: approle
          roleId: ${{ secrets.VAULT_ROLE_ID }}
          secretId: ${{ secrets.VAULT_SECRET_ID }}
          secrets: |
            secret/data/openai api_key | OPENAI_API_KEY

      # Install dependencies
      - name: Install dependencies
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip
          pip install --no-cache-dir openai faiss-cpu pyyaml

      # Validate secret
      - name: Validate OpenAI Key
        run: |
          if [ -z "${OPENAI_API_KEY}" ]; then
            echo "âŒ OPENAI_API_KEY missing"
            exit 1
          fi
          echo "OPENAI_API_KEY prefix: ${OPENAI_API_KEY:0:7}******"
        env:
          OPENAI_API_KEY: ${{ steps.vault.outputs.OPENAI_API_KEY }}

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: ${{ env.JAVA_VERSION }}
          cache: maven

      - name: Build AST Engine
        run: |
          set -euxo pipefail
          cd tools/java-ast-fixer
          mvn -B clean package
          ls -la target/

      # Run Agent
      - name: Run Agent
        run: python -m tools.agent.run_agent
        env:
          OPENAI_API_KEY: ${{ steps.vault.outputs.OPENAI_API_KEY }}
          PYTHONPATH: .
          RAG_DEBUG: "true"

      - uses: actions/upload-artifact@v4
        with:
          name: ai-results
          path: agent_output/*
          if-no-files-found: ignore

      # =====================================================
      # CREATE PR (only if branch metadata exists)
      # =====================================================
      - name: Create PR via API
        if: hashFiles('agent_output/agent_meta.json') != ''
        uses: actions/github-script@v7
        env:
          BASE_BRANCH: ${{ env.BASE_BRANCH }}
        with:
          script: |
            const fs = require('fs');
            const meta = JSON.parse(fs.readFileSync('agent_output/agent_meta.json', 'utf8'));
            const branch = meta.branch;

            const { owner, repo } = context.repo;

            // Check if PR already exists
            const existing = await github.rest.pulls.list({
              owner,
              repo,
              state: 'open',
              head: `${owner}:${branch}`
            });

            if (existing.data.length > 0) {
              console.log("PR already exists:", existing.data[0].html_url);
              return;
            }

            const pr = await github.rest.pulls.create({
              owner,
              repo,
              title: "Agentic AI Autofix",
              head: branch,
              base: process.env.BASE_BRANCH,
              body: "Automated security patch generated by Agentic AI."
            });

            console.log("PR created:", pr.data.html_url);

      # =====================================================
      # BUILD PR COMMENT BODY
      # =====================================================
      - name: Build PR comment body
        if: hashFiles('agent_output/agent_meta.json') != ''
        run: |
          {
            echo "### ðŸ¤– Agentic AI â€” Autofix Summary"
            echo ""
            echo "- **Aggregate Decision**: \`${{ needs.Aggregate-Scanning-Reports.outputs.decision }}\`"
            echo ""
            if [ -f agent_output/agent_patch.diff ]; then
              echo "<details><summary>Generated Diff (first 200 lines)</summary>"
              echo
              head -n 200 agent_output/agent_patch.diff | sed 's/^/    /'
              echo
              echo "</details>"
            else
              echo "_No patch file found._"
            fi
          } > agent_output/pr_comment.md

      # =====================================================
      # POST PR COMMENT
      # =====================================================
      - name: Post PR comment
        if: hashFiles('agent_output/agent_meta.json') != ''
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const meta = JSON.parse(fs.readFileSync('agent_output/agent_meta.json', 'utf8'));
            const branch = meta.branch;
            const body = fs.readFileSync('agent_output/pr_comment.md', 'utf8');

            const { owner, repo } = context.repo;

            const { data: prs } = await github.rest.pulls.list({
              owner,
              repo,
              state: 'open',
              head: `${owner}:${branch}`
            });

            if (!prs.length) {
              console.log("No open PR found for branch:", branch);
              return;
            }

            await github.rest.issues.createComment({
              owner,
              repo,
              issue_number: prs[0].number,
              body
            });

            console.log("Comment posted to PR:", prs[0].html_url);