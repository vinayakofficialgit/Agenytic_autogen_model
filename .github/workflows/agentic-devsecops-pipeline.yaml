

###########################test
name: DevSecOps Agentic AI Pipeline

on:
  push:
    branches: [main, test-v-branch]
  pull_request:
    branches: [main, test-v-branch]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"
  APP_DIR: "Order-app-main"
  REPORTS_DIR: "reports"
  OUTPUT_DIR: "agent_output"
  ACTIONS_STEP_DEBUG: "true"  
  LLM_ENABLED: ${{ secrets.LLM_ENABLED }}
  LLM_AUTOFIX: ${{ secrets.LLM_AUTOFIX }}   
  OLLAMA_MODEL: ${{ secrets.OLLAMA_MODEL }}
  OLLAMA_NUM_CTX: ${{ secrets.OLLAMA_NUM_CTX }}
  OLLAMA_NUM_PREDICT: ${{ secrets.OLLAMA_NUM_PREDICT }}
  OLLAMA_TEMPERATURE: ${{ secrets.OLLAMA_TEMPERATURE }}
  MIN_SEVERITY: ${{ secrets.MIN_SEVERITY }}
  LLM_AUTOFIX_TOOLS: ${{ secrets.LLM_AUTOFIX_TOOLS }}
  


jobs:
# ============================================================
# JOB 1: SECURITY SCANS
# ============================================================
  security-scan:
    name: ðŸ” Security Scan
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      
      # THIS STEP must be repeated in every job
      - name: Setup Python & Venv
        run: |
          sudo apt update && sudo apt install -y python3-venv
          python3 -m venv envmine
          # This makes 'pip' and 'python' use the venv automatically for this job
          echo "$GITHUB_WORKSPACE/envmine/bin" >> $GITHUB_PATH

      - name: Install Dependencies
        run: |
          # Now this uses the venv pip automatically!
          pip install -r requirements.txt

    
      
     ## ---------------- SEMGREP (CODE) ----------------
      - name: Run Semgrep (Application)
        run: |
          set -e
          pip install semgrep
          semgrep scan \
            --config=auto \
            --json \
            --output $REPORTS_DIR/semgrep.json \
            $APP_DIR
          test -f $REPORTS_DIR/semgrep.json
      
      - name: Run Trivy FS (Application)
        run: |
          set -e
      
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh
          sudo mv ./bin/trivy /usr/local/bin/trivy
      
          trivy version
      
          trivy fs \
            --format json \
            --output $REPORTS_DIR/trivy_fs.json \
            $APP_DIR
      
          test -f $REPORTS_DIR/trivy_fs.json


      # ---------------- TRIVY IMAGE () ----------------
      - name: Run Trivy Image (if Dockerfile exists)
        run: |
          set -e
          if [ -f "$APP_DIR/Dockerfile" ]; then
            docker build -t order-app:scan $APP_DIR
            trivy image \
              --format json \
              --output $REPORTS_DIR/trivy_image.json \
              order-app:scan
          else
            echo '{}' > $REPORTS_DIR/trivy_image.json
          fi
          test -f $REPORTS_DIR/trivy_image.json


      # ---------------- TFSEC ----------------
      - name: Install tfsec
        run: |
          set -e
          curl -sfL https://raw.githubusercontent.com/aquasecurity/tfsec/master/scripts/install_linux.sh | bash

      - name: Run tfsec
        run: |
          set -e
          tfsec terraform --format json \
            > "$REPORTS_DIR/tfsec.json" || true
          test -f "$REPORTS_DIR/tfsec.json"

      # ---------------- GITLEAKS ----------------
      - name: Install Gitleaks
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y jq
          VERSION=$(curl -s https://api.github.com/repos/gitleaks/gitleaks/releases/latest | jq -r .tag_name)
          curl -sL https://github.com/gitleaks/gitleaks/releases/download/${VERSION}/gitleaks_${VERSION#v}_linux_x64.tar.gz \
            | tar -xz
          sudo mv gitleaks /usr/local/bin/

      - name: Run Gitleaks
        run: |
          set -e
          gitleaks detect --source . --report-format json \
            --report-path "$REPORTS_DIR/gitleaks.json" --no-git || true
          test -f "$REPORTS_DIR/gitleaks.json"

      # ---------------- CONFTEST (POLICY) ----------------
      - name: Install Conftest
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y jq curl
      
          VERSION=$(curl -s https://api.github.com/repos/open-policy-agent/conftest/releases/latest | jq -r .tag_name)
          echo "Installing conftest $VERSION"
      
          curl -sL https://github.com/open-policy-agent/conftest/releases/download/${VERSION}/conftest_${VERSION#v}_Linux_x86_64.tar.gz \
            | tar -xz
      
          sudo mv conftest /usr/local/bin/
          conftest --version

      - name: Run Conftest (Policies)
        run: |
            set -e
            conftest test k8s terraform policy \
              --output json \
              > "$REPORTS_DIR/conftest.json" || echo "[]" > "$REPORTS_DIR/conftest.json"
        
            test -f "$REPORTS_DIR/conftest.json"
          


      - name: Upload scan reports
        uses: actions/upload-artifact@v4
        with:
          name: scan-reports
          path: reports/




# ============================================================
# JOB 2: AI ANALYSIS (OLLAMA ENABLED)
# ============================================================
  llm-agent-analysis:
    name: ðŸ¤– Agentic AI Analysis
    runs-on: ubuntu-latest
    needs: security-scan

    outputs:
      pipeline_status: ${{ steps.status.outputs.pipeline_status }}

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Python & Venv
        run: |
          sudo apt update && sudo apt install -y python3-venv
          python3 -m venv envmine
          # This makes 'pip' and 'python' use the venv automatically for this job
          echo "$GITHUB_WORKSPACE/envmine/bin" >> $GITHUB_PATH

      - name: Install Dependencies
        run: |
          # Now this uses the venv pip automatically!
          pip install -r requirements.txt

      - run: pip install pyyaml requests jq

      - uses: actions/download-artifact@v4
        with:
          name: scan-reports
          path: reports/

      # ---------- START OLLAMA ----------
      - name: Start Ollama
        run: |
          set -e
          curl -fsSL https://ollama.com/install.sh | sh
          nohup ollama serve > /tmp/ollama.log 2>&1 &
          sleep 10
          ollama pull "$OLLAMA_MODEL"

      - name: Run agentic analysis
        run: |
          python main.py --verbose || true

      - name: Capture decision
        id: status
        run: |
          STATUS=$(jq -r '.status' "$OUTPUT_DIR/decision.json")
          echo "pipeline_status=$STATUS" >> "$GITHUB_OUTPUT"

      - uses: actions/upload-artifact@v4
        with:
          name: ai-results
          path: agent_output/
          
# # ============================================================
#   # JOB 3: REMEDIATION SUGGESTIONS (LLM generates fix files)
#   #
#   # OUTPUT STRUCTURE (in remediation-suggestions/ folder):
#   #   remediation-suggestions/
#   #   â”œâ”€â”€ README.md                        â† overview + how to apply
#   #   â”œâ”€â”€ semgrep_suggestions.py           â† Python/app code fixes
#   #   â”œâ”€â”€ trivy_fs_suggestions.md          â† filesystem vulnerability fixes
#   #   â”œâ”€â”€ trivy_image_suggestions.md       â† container image fixes
#   #   â”œâ”€â”€ tfsec_suggestions.tf             â† copy-paste Terraform fixes
#   #   â”œâ”€â”€ gitleaks_suggestions.md          â† secrets remediation steps
#   #   â”œâ”€â”€ conftest_suggestions.yaml        â† policy-compliant K8s/TF snippets
#   #   â”œâ”€â”€ llm_analysis_recommendations.md  â† full LLM analysis from Job 2
#   #   â””â”€â”€ remediation_summary.json         â† machine-readable summary
#   #
#   # NO SOURCE CODE IS MODIFIED.
#   # ============================================================
#   remediation-suggestions:
#     name: ðŸ’¡ Remediation Suggestions
#     runs-on: ubuntu-latest
#     needs: llm-agent-analysis
#     if: >-
#       always() &&
#       github.event_name == 'push' &&
#       needs.llm-agent-analysis.outputs.pipeline_status == 'fail'

#     outputs:
#       suggestions_created: ${{ steps.generate.outputs.suggestions_created }}

#     permissions:
#       contents: write
#       pull-requests: write

#     steps:
#       - uses: actions/checkout@v4
#         with:
#           fetch-depth: 0

#       - uses: actions/setup-python@v5
#         with:
#           python-version: ${{ env.PYTHON_VERSION }}

#       - name: Install Python dependencies
#         run: pip install pyyaml requests jq

#       - uses: actions/download-artifact@v4
#         with:
#           name: scan-reports
#           path: reports/

#       - uses: actions/download-artifact@v4
#         with:
#           name: ai-results
#           path: agent_output/

#       - name: Start Ollama
#         run: |
#           set -e
#           curl -fsSL https://ollama.com/install.sh | sh
#           nohup ollama serve > /tmp/ollama.log 2>&1 &
#           for i in $(seq 1 30); do
#             curl -sf http://localhost:11434/api/tags > /dev/null 2>&1 && break
#             sleep 2
#           done
#           ollama pull "$OLLAMA_MODEL"

#       - name: Generate remediation suggestions
#         id: generate
#         env:
#           OLLAMA_URL: "http://localhost:11434"
#         run: |
#           set -e
#           mkdir -p remediation-suggestions

#           python3 << 'PYEOF'
#           import json, os, sys, requests, yaml
#           from pathlib import Path
#           from datetime import datetime

#           REPORTS = Path("reports")
#           SUGGESTIONS = Path("remediation-suggestions")
#           AGENT_OUTPUT = Path("agent_output")
#           OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
#           OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5-coder:7b")

#           def llm_ask(system_prompt: str, user_prompt: str) -> str:
#               """Ask Ollama for a suggestion. Returns empty string on failure."""
#               try:
#                   resp = requests.post(
#                       f"{OLLAMA_URL}/api/chat",
#                       json={
#                           "model": OLLAMA_MODEL,
#                           "messages": [
#                               {"role": "system", "content": system_prompt},
#                               {"role": "user", "content": user_prompt},
#                           ],
#                           "stream": False,
#                           "options": {
#                               "temperature": 0.2,
#                               "num_predict": int(os.getenv("OLLAMA_NUM_PREDICT", "2048")),
#                           },
#                       },
#                       timeout=120,
#                   )
#                   resp.raise_for_status()
#                   return resp.json().get("message", {}).get("content", "")
#               except Exception as e:
#                   print(f"[LLM Error] {e}")
#                   return ""

#           def load_json(path: Path) -> dict | list:
#               try:
#                   return json.loads(path.read_text())
#               except Exception:
#                   return {}

#           summary = {
#               "generated_at": datetime.utcnow().isoformat() + "Z",
#               "tools": {},
#               "total_findings": 0,
#               "total_suggestions": 0,
#           }

#           readme_sections = []
#           readme_sections.append("# ðŸ”§ Remediation Suggestions\n")
#           readme_sections.append(f"Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\n")
#           readme_sections.append("These are **LLM-generated suggestions** for review. ")
#           readme_sections.append("**No source code was modified.** Review each suggestion ")
#           readme_sections.append("carefully before applying.\n")
#           readme_sections.append("---\n")

#           # ==============================================================
#           # SEMGREP (Application code â€” Python, JS, etc.)
#           # Report: reports/semgrep.json
#           # ==============================================================
#           semgrep_data = load_json(REPORTS / "semgrep.json")
#           semgrep_results = semgrep_data.get("results", []) if isinstance(semgrep_data, dict) else []

#           if semgrep_results:
#               print(f"[semgrep] Processing {len(semgrep_results)} finding(s)...")
#               sg_suggestions = []
#               sg_suggestions.append("# ==================================================")
#               sg_suggestions.append("# SEMGREP REMEDIATION SUGGESTIONS")
#               sg_suggestions.append("# Generated by DevSecOps Agentic AI Pipeline")
#               sg_suggestions.append("# Review carefully before applying to your source files")
#               sg_suggestions.append("# ==================================================\n")

#               for i, finding in enumerate(semgrep_results, 1):
#                   check_id = finding.get("check_id", "")
#                   severity = finding.get("extra", {}).get("severity", "UNKNOWN")
#                   message = finding.get("extra", {}).get("message", "")
#                   filepath = finding.get("path", "unknown")
#                   start_line = finding.get("start", {}).get("line", "?")
#                   end_line = finding.get("end", {}).get("line", "?")
#                   # Try to get the matched code snippet
#                   snippet = finding.get("extra", {}).get("lines", "")
#                   if not snippet:
#                       snippet = finding.get("extra", {}).get("matched_code", "")

#                   prompt = (
#                       f"Semgrep finding:\n"
#                       f"- Rule: {check_id}\n"
#                       f"- Severity: {severity}\n"
#                       f"- File: {filepath} (lines {start_line}-{end_line})\n"
#                       f"- Message: {message}\n"
#                       f"- Vulnerable code:\n```\n{snippet}\n```\n\n"
#                       f"Tasks:\n"
#                       f"1. Explain the vulnerability in 1-2 lines\n"
#                       f"2. Generate the CORRECTED code that fixes this issue\n"
#                       f"3. Show exactly which file and line numbers to replace\n"
#                       f"4. Note any imports or dependencies needed\n\n"
#                       f"Output the corrected code in a code block with the language specified."
#                   )

#                   suggestion = llm_ask(
#                       "You are a senior application security engineer. Generate safe, minimal "
#                       "code fixes. Always show the corrected code block with the target file "
#                       "and line numbers. Never introduce new vulnerabilities.",
#                       prompt,
#                   )

#                   sg_suggestions.append(f"# --- Finding {i}: {check_id} [{severity}] ---")
#                   sg_suggestions.append(f"# File: {filepath} (lines {start_line}-{end_line})")
#                   sg_suggestions.append(f"# Issue: {message[:200]}")
#                   sg_suggestions.append(f"# Vulnerable code:")
#                   for line in str(snippet).splitlines():
#                       sg_suggestions.append(f"#   {line}")
#                   sg_suggestions.append(f"#")
#                   sg_suggestions.append(f"# --- Suggested fix ---")
#                   if suggestion.strip():
#                       sg_suggestions.append(suggestion.strip())
#                   else:
#                       sg_suggestions.append("# [LLM could not generate a suggestion for this finding]")
#                   sg_suggestions.append("\n")

#               (SUGGESTIONS / "semgrep_suggestions.py").write_text("\n".join(sg_suggestions))
#               summary["tools"]["semgrep"] = {"findings": len(semgrep_results), "suggestions": len(semgrep_results)}
#               summary["total_findings"] += len(semgrep_results)
#               summary["total_suggestions"] += len(semgrep_results)

#               readme_sections.append(f"## ðŸ Application Code (Semgrep) â€” {len(semgrep_results)} finding(s)\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/semgrep_suggestions.py`\n")
#               readme_sections.append("**How to apply:** Review each finding, copy the corrected code ")
#               readme_sections.append("into the indicated file at the specified line numbers.\n")
#           else:
#               print("[semgrep] No findings or report not found.")

#           # ==============================================================
#           # TRIVY FS (Filesystem â€” misconfigs, vulnerabilities in code)
#           # Report: reports/trivy_fs.json
#           # ==============================================================
#           trivy_fs_data = load_json(REPORTS / "trivy_fs.json")
#           trivy_fs_results = []
#           if isinstance(trivy_fs_data, dict):
#               for result in trivy_fs_data.get("Results", []):
#                   target = result.get("Target", "")
#                   # Misconfigurations
#                   for misconf in result.get("Misconfigurations", []):
#                       trivy_fs_results.append({
#                           "type": "misconfiguration",
#                           "target": target,
#                           "id": misconf.get("ID", ""),
#                           "title": misconf.get("Title", ""),
#                           "description": misconf.get("Description", ""),
#                           "severity": misconf.get("Severity", "UNKNOWN"),
#                           "resolution": misconf.get("Resolution", ""),
#                           "primary_url": misconf.get("PrimaryURL", ""),
#                       })
#                   # Vulnerabilities
#                   for vuln in result.get("Vulnerabilities", []):
#                       trivy_fs_results.append({
#                           "type": "vulnerability",
#                           "target": target,
#                           "id": vuln.get("VulnerabilityID", ""),
#                           "pkg_name": vuln.get("PkgName", ""),
#                           "installed": vuln.get("InstalledVersion", ""),
#                           "fixed": vuln.get("FixedVersion", ""),
#                           "severity": vuln.get("Severity", "UNKNOWN"),
#                           "title": vuln.get("Title", ""),
#                           "description": vuln.get("Description", ""),
#                           "primary_url": vuln.get("PrimaryURL", ""),
#                       })

#           if trivy_fs_results:
#               print(f"[trivy_fs] Processing {len(trivy_fs_results)} finding(s)...")
#               tfs_suggestions = []
#               tfs_suggestions.append("# ðŸ” Trivy Filesystem Remediation Suggestions\n")
#               tfs_suggestions.append("Generated by DevSecOps Agentic AI Pipeline.\n")
#               tfs_suggestions.append("---\n")

#               for i, finding in enumerate(trivy_fs_results, 1):
#                   if finding["type"] == "misconfiguration":
#                       prompt = (
#                           f"Trivy filesystem misconfiguration:\n"
#                           f"- ID: {finding['id']}\n"
#                           f"- Severity: {finding['severity']}\n"
#                           f"- File: {finding['target']}\n"
#                           f"- Title: {finding['title']}\n"
#                           f"- Description: {finding['description'][:300]}\n"
#                           f"- Recommended resolution: {finding['resolution']}\n\n"
#                           f"Provide the corrected configuration code that fixes this misconfiguration. "
#                           f"Show the exact file and what to change."
#                       )
#                   else:
#                       prompt = (
#                           f"Trivy filesystem vulnerability:\n"
#                           f"- CVE: {finding['id']}\n"
#                           f"- Severity: {finding['severity']}\n"
#                           f"- Package: {finding.get('pkg_name', '')} "
#                           f"(installed: {finding.get('installed', '')}, "
#                           f"fixed: {finding.get('fixed', 'N/A')})\n"
#                           f"- File: {finding['target']}\n"
#                           f"- Title: {finding.get('title', '')}\n\n"
#                           f"Provide step-by-step remediation:\n"
#                           f"1. How to update the vulnerable package\n"
#                           f"2. The exact command or file change needed\n"
#                           f"3. Any breaking changes to watch for"
#                       )

#                   suggestion = llm_ask(
#                       "You are a cloud security engineer specializing in infrastructure "
#                       "and dependency security. Provide safe, actionable remediation steps.",
#                       prompt,
#                   )

#                   tfs_suggestions.append(f"## Finding {i}: `{finding['id']}` [{finding['severity']}]\n")
#                   tfs_suggestions.append(f"**File:** `{finding['target']}`\n")
#                   if finding["type"] == "misconfiguration":
#                       tfs_suggestions.append(f"**Title:** {finding['title']}\n")
#                   else:
#                       tfs_suggestions.append(f"**Package:** {finding.get('pkg_name', '')} "
#                                               f"({finding.get('installed', '')} â†’ {finding.get('fixed', 'N/A')})\n")
#                   if suggestion.strip():
#                       tfs_suggestions.append(suggestion.strip())
#                   else:
#                       tfs_suggestions.append("*LLM could not generate a suggestion.*")
#                   tfs_suggestions.append("\n---\n")

#               (SUGGESTIONS / "trivy_fs_suggestions.md").write_text("\n".join(tfs_suggestions))
#               summary["tools"]["trivy_fs"] = {"findings": len(trivy_fs_results), "suggestions": len(trivy_fs_results)}
#               summary["total_findings"] += len(trivy_fs_results)
#               summary["total_suggestions"] += len(trivy_fs_results)

#               readme_sections.append(f"## ðŸ” Filesystem Scan (Trivy FS) â€” {len(trivy_fs_results)} finding(s)\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/trivy_fs_suggestions.md`\n")
#               readme_sections.append("**How to apply:** Follow the remediation steps for each finding. ")
#               readme_sections.append("Update packages or fix misconfigurations as indicated.\n")
#           else:
#               print("[trivy_fs] No findings or report not found.")

#           # ==============================================================
#           # TRIVY IMAGE (Container image vulnerabilities)
#           # Report: reports/trivy_image.json
#           # ==============================================================
#           trivy_img_data = load_json(REPORTS / "trivy_image.json")
#           trivy_img_results = []
#           if isinstance(trivy_img_data, dict):
#               for result in trivy_img_data.get("Results", []):
#                   target = result.get("Target", "")
#                   for vuln in result.get("Vulnerabilities", []):
#                       trivy_img_results.append({
#                           "target": target,
#                           "id": vuln.get("VulnerabilityID", ""),
#                           "pkg_name": vuln.get("PkgName", ""),
#                           "installed": vuln.get("InstalledVersion", ""),
#                           "fixed": vuln.get("FixedVersion", ""),
#                           "severity": vuln.get("Severity", "UNKNOWN"),
#                           "title": vuln.get("Title", ""),
#                       })

#           if trivy_img_results:
#               print(f"[trivy_image] Processing {len(trivy_img_results)} finding(s)...")
#               ti_suggestions = []
#               ti_suggestions.append("# ðŸ³ Trivy Image Remediation Suggestions\n")
#               ti_suggestions.append("These findings are from scanning the container image.\n")
#               ti_suggestions.append("---\n")

#               for i, finding in enumerate(trivy_img_results, 1):
#                   prompt = (
#                       f"Container image vulnerability:\n"
#                       f"- CVE: {finding['id']}\n"
#                       f"- Severity: {finding['severity']}\n"
#                       f"- Image layer: {finding['target']}\n"
#                       f"- Package: {finding['pkg_name']} "
#                       f"(installed: {finding['installed']}, fixed: {finding['fixed'] or 'N/A'})\n"
#                       f"- Title: {finding.get('title', '')}\n\n"
#                       f"Provide remediation:\n"
#                       f"1. Dockerfile changes needed (e.g., base image update, package pin)\n"
#                       f"2. The exact Dockerfile line to modify\n"
#                       f"3. Any multi-stage build optimizations"
#                   )

#                   suggestion = llm_ask(
#                       "You are a container security expert. Provide Dockerfile fixes "
#                       "that resolve vulnerabilities while keeping images minimal and secure.",
#                       prompt,
#                   )

#                   ti_suggestions.append(f"## Finding {i}: `{finding['id']}` [{finding['severity']}]\n")
#                   ti_suggestions.append(f"**Image layer:** `{finding['target']}`\n")
#                   ti_suggestions.append(f"**Package:** {finding['pkg_name']} "
#                                          f"({finding['installed']} â†’ {finding['fixed'] or 'N/A'})\n")
#                   if suggestion.strip():
#                       ti_suggestions.append(suggestion.strip())
#                   else:
#                       ti_suggestions.append("*LLM could not generate a suggestion.*")
#                   ti_suggestions.append("\n---\n")

#               (SUGGESTIONS / "trivy_image_suggestions.md").write_text("\n".join(ti_suggestions))
#               summary["tools"]["trivy_image"] = {"findings": len(trivy_img_results), "suggestions": len(trivy_img_results)}
#               summary["total_findings"] += len(trivy_img_results)
#               summary["total_suggestions"] += len(trivy_img_results)

#               readme_sections.append(f"## ðŸ³ Container Image (Trivy Image) â€” {len(trivy_img_results)} finding(s)\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/trivy_image_suggestions.md`\n")
#               readme_sections.append("**How to apply:** Update your Dockerfile with the suggested base image ")
#               readme_sections.append("or package version changes.\n")
#           else:
#               print("[trivy_image] No findings or report not found.")

#           # ==============================================================
#           # TFSEC (Terraform security)
#           # Report: reports/tfsec.json
#           # ==============================================================
#           tfsec_data = load_json(REPORTS / "tfsec.json")
#           tfsec_results = tfsec_data.get("results", []) if isinstance(tfsec_data, dict) else []

#           if tfsec_results:
#               print(f"[tfsec] Processing {len(tfsec_results)} finding(s)...")
#               tf_suggestions = []
#               tf_suggestions.append("# ==============================================")
#               tf_suggestions.append("# TFSEC REMEDIATION SUGGESTIONS")
#               tf_suggestions.append("# Generated by DevSecOps Agentic AI Pipeline")
#               tf_suggestions.append("# Review carefully before applying to your .tf files")
#               tf_suggestions.append("# ==============================================\n")

#               for i, finding in enumerate(tfsec_results, 1):
#                   severity = finding.get("severity", "UNKNOWN")
#                   rule_id = finding.get("rule_id", finding.get("long_id", ""))
#                   desc = finding.get("description", "")
#                   filename = finding.get("location", {}).get("filename", "unknown")
#                   start_line = finding.get("location", {}).get("start_line", "?")
#                   end_line = finding.get("location", {}).get("end_line", "?")

#                   prompt = (
#                       f"tfsec finding:\n"
#                       f"- Rule: {rule_id}\n"
#                       f"- Severity: {severity}\n"
#                       f"- File: {filename} (lines {start_line}-{end_line})\n"
#                       f"- Description: {desc}\n\n"
#                       f"Generate the corrected Terraform code block that fixes this issue. "
#                       f"Output ONLY the corrected HCL code wrapped in a Terraform code block. "
#                       f"Add a comment showing which file and line to apply it to."
#                   )

#                   suggestion = llm_ask(
#                       "You are a Terraform security expert. Generate safe, minimal Terraform fixes. "
#                       "Output only HCL code blocks with comments indicating the target file and line.",
#                       prompt,
#                   )

#                   tf_suggestions.append(f"# --- Finding {i}: {rule_id} [{severity}] ---")
#                   tf_suggestions.append(f"# File: {filename} (lines {start_line}-{end_line})")
#                   tf_suggestions.append(f"# Issue: {desc}")
#                   if suggestion.strip():
#                       tf_suggestions.append(suggestion.strip())
#                   else:
#                       tf_suggestions.append(f"# [LLM could not generate a suggestion for this finding]")
#                   tf_suggestions.append("")

#               (SUGGESTIONS / "tfsec_suggestions.tf").write_text("\n".join(tf_suggestions))
#               summary["tools"]["tfsec"] = {"findings": len(tfsec_results), "suggestions": len(tfsec_results)}
#               summary["total_findings"] += len(tfsec_results)
#               summary["total_suggestions"] += len(tfsec_results)

#               readme_sections.append(f"## ðŸ—ï¸ Terraform (tfsec) â€” {len(tfsec_results)} finding(s)\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/tfsec_suggestions.tf`\n")
#               readme_sections.append("**How to apply:** Copy the corrected code blocks into your `.tf` files ")
#               readme_sections.append("at the indicated file and line numbers.\n")
#           else:
#               print("[tfsec] No findings.")

#           # ==============================================================
#           # GITLEAKS (Secrets detection)
#           # Report: reports/gitleaks.json
#           # ==============================================================
#           gitleaks_data = load_json(REPORTS / "gitleaks.json")
#           gitleaks_results = gitleaks_data if isinstance(gitleaks_data, list) else []

#           if gitleaks_results:
#               print(f"[gitleaks] Processing {len(gitleaks_results)} finding(s)...")
#               gl_suggestions = []
#               gl_suggestions.append("# ðŸ”‘ Gitleaks Remediation Suggestions\n")
#               gl_suggestions.append("These findings indicate potential secrets in your codebase.\n")
#               gl_suggestions.append("---\n")

#               for i, finding in enumerate(gitleaks_results, 1):
#                   rule = finding.get("RuleID", finding.get("rule", ""))
#                   match_val = finding.get("Match", finding.get("match", ""))[:40] + "..."
#                   filename = finding.get("File", finding.get("file", ""))
#                   line = finding.get("StartLine", finding.get("line", "?"))

#                   prompt = (
#                       f"Gitleaks finding:\n"
#                       f"- Rule: {rule}\n"
#                       f"- File: {filename} (line {line})\n"
#                       f"- Match preview: {match_val}\n\n"
#                       f"Provide step-by-step remediation:\n"
#                       f"1. How to remove/rotate the secret\n"
#                       f"2. How to prevent re-commit (e.g., .gitignore, env vars)\n"
#                       f"3. Git history cleanup command if needed"
#                   )

#                   suggestion = llm_ask(
#                       "You are a secrets management expert. Provide clear, actionable steps. "
#                       "Never include the actual secret in your response.",
#                       prompt,
#                   )

#                   gl_suggestions.append(f"## Finding {i}: `{rule}` in `{filename}:{line}`\n")
#                   if suggestion.strip():
#                       gl_suggestions.append(suggestion.strip())
#                   else:
#                       gl_suggestions.append("*LLM could not generate a suggestion.*")
#                   gl_suggestions.append("\n---\n")

#               (SUGGESTIONS / "gitleaks_suggestions.md").write_text("\n".join(gl_suggestions))
#               summary["tools"]["gitleaks"] = {"findings": len(gitleaks_results), "suggestions": len(gitleaks_results)}
#               summary["total_findings"] += len(gitleaks_results)
#               summary["total_suggestions"] += len(gitleaks_results)

#               readme_sections.append(f"## ðŸ”‘ Secrets (Gitleaks) â€” {len(gitleaks_results)} finding(s)\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/gitleaks_suggestions.md`\n")
#               readme_sections.append("**How to apply:** Follow the step-by-step instructions to rotate ")
#               readme_sections.append("secrets and clean git history.\n")
#           else:
#               print("[gitleaks] No findings.")

#           # ==============================================================
#           # CONFTEST (Policy violations)
#           # Report: reports/conftest.json
#           # ==============================================================
#           conftest_data = load_json(REPORTS / "conftest.json")
#           conftest_failures = []
#           if isinstance(conftest_data, list):
#               for entry in conftest_data:
#                   if isinstance(entry, dict):
#                       for f in entry.get("failures", []):
#                           conftest_failures.append({
#                               "file": entry.get("filename", ""),
#                               "msg": f.get("msg", "") if isinstance(f, dict) else str(f),
#                           })

#           if conftest_failures:
#               print(f"[conftest] Processing {len(conftest_failures)} failure(s)...")
#               ct_suggestions = []

#               for i, failure in enumerate(conftest_failures, 1):
#                   filename = failure.get("file", "unknown")
#                   msg = failure.get("msg", "")

#                   prompt = (
#                       f"Conftest policy failure:\n"
#                       f"- File: {filename}\n"
#                       f"- Policy violation: {msg}\n\n"
#                       f"Generate the corrected YAML or HCL snippet that satisfies this policy. "
#                       f"Output ONLY the corrected code with a comment showing the target file."
#                   )

#                   suggestion = llm_ask(
#                       "You are a Kubernetes/Terraform policy expert. Generate minimal, "
#                       "policy-compliant code fixes. Output corrected YAML or HCL only.",
#                       prompt,
#                   )

#                   ct_suggestions.append(f"# --- Policy Failure {i} ---")
#                   ct_suggestions.append(f"# File: {filename}")
#                   ct_suggestions.append(f"# Violation: {msg}")
#                   if suggestion.strip():
#                       ct_suggestions.append(suggestion.strip())
#                   else:
#                       ct_suggestions.append("# [LLM could not generate a suggestion]")
#                   ct_suggestions.append("")

#               (SUGGESTIONS / "conftest_suggestions.yaml").write_text("\n".join(ct_suggestions))
#               summary["tools"]["conftest"] = {"findings": len(conftest_failures), "suggestions": len(conftest_failures)}
#               summary["total_findings"] += len(conftest_failures)
#               summary["total_suggestions"] += len(conftest_failures)

#               readme_sections.append(f"## ðŸ“‹ Policy (Conftest) â€” {len(conftest_failures)} failure(s)\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/conftest_suggestions.yaml`\n")
#               readme_sections.append("**How to apply:** Copy the corrected YAML/HCL into the target files.\n")
#           else:
#               print("[conftest] No failures.")

#           # ==============================================================
#           # INCLUDE LLM RECOMMENDATIONS FROM AI ANALYSIS (Job 2)
#           # ==============================================================
#           llm_reco = AGENT_OUTPUT / "llm_recommendations.md"
#           if llm_reco.exists():
#               content = llm_reco.read_text()
#               (SUGGESTIONS / "llm_analysis_recommendations.md").write_text(content)
#               readme_sections.append("## ðŸ¤– LLM Analysis Recommendations\n")
#               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/llm_analysis_recommendations.md`\n")
#               readme_sections.append("Full LLM analysis from the AI pipeline.\n")

#           # ---- WRITE SUMMARY JSON ----
#           (SUGGESTIONS / "remediation_summary.json").write_text(
#               json.dumps(summary, indent=2)
#           )

#           # ---- WRITE README ----
#           if summary["total_findings"] == 0:
#               readme_sections.append("## âœ… No actionable findings\n")
#               readme_sections.append("All scans passed or produced no parseable findings.\n")

#           readme_sections.append("---\n")
#           readme_sections.append("## How to use this PR\n")
#           readme_sections.append("1. **Review** each suggestion file in `remediation-suggestions/`\n")
#           readme_sections.append("2. **Copy-paste** the corrected code into your source files\n")
#           readme_sections.append("3. **Test** your changes locally\n")
#           readme_sections.append("4. **Commit** to your branch\n")
#           readme_sections.append("5. **Close** this PR once all suggestions are applied or dismissed\n")
#           readme_sections.append("\n> âš ï¸ These are AI-generated suggestions. Always review before applying.\n")

#           (SUGGESTIONS / "README.md").write_text("\n".join(readme_sections))

#           has_suggestions = summary["total_suggestions"] > 0
#           print(f"\nâœ… Generated {summary['total_suggestions']} suggestion(s) across {len(summary['tools'])} tool(s)")

#           with open(os.environ["GITHUB_OUTPUT"], "a") as f:
#               f.write(f"suggestions_created={'true' if has_suggestions else 'false'}\n")

#           PYEOF

#       - name: Show generated suggestions
#         run: |
#           echo "=== Suggestion files ==="
#           ls -la remediation-suggestions/ || echo "No files"
#           echo ""
#           echo "=== README.md ==="
#           cat remediation-suggestions/README.md 2>/dev/null || echo "Not found"
#           echo ""
#           echo "=== Summary ==="
#           cat remediation-suggestions/remediation_summary.json 2>/dev/null || echo "Not found"

#       - name: Upload suggestion artifacts
#         uses: actions/upload-artifact@v4
#         with:
#           name: remediation-suggestions
#           path: remediation-suggestions/

#       - name: Generate unique branch name
#         id: branch
#         run: |
#           BRANCH="remediation/suggestions-run-${{ github.run_number }}"
#           echo "name=$BRANCH" >> "$GITHUB_OUTPUT"

#       - name: Create suggestions PR
#         if: steps.generate.outputs.suggestions_created == 'true'
#         uses: peter-evans/create-pull-request@v6
#         with:
#           token: ${{ secrets.GITHUB_TOKEN }}
#           branch: ${{ steps.branch.outputs.name }}
#           base: test-v-branch
#           delete-branch: true
#           add-paths: remediation-suggestions/**
#           title: "ðŸ’¡ Security Remediation Suggestions (Run #${{ github.run_number }})"
#           commit-message: "docs: add LLM-generated remediation suggestions"
#           body: |
#             ## ðŸ’¡ AI-Generated Remediation Suggestions

#             **Run:** #${{ github.run_number }}
#             **Trigger:** Security scan found issues that need attention.

#             ### ðŸ“ What's in this PR

#             This PR contains **suggestion files only** â€” no source code was modified.

#             | Folder | Contents |
#             |--------|----------|
#             | `remediation-suggestions/` | Per-tool fix suggestions you can copy-paste |

#             ### ðŸ“‹ How to use

#             1. Review each file in `remediation-suggestions/`
#             2. Copy the corrected code into your source files
#             3. Test locally
#             4. Commit your changes
#             5. Close this PR

#             > âš ï¸ **These are AI-generated suggestions. Always review before applying.**

#             ---
#             _Generated by DevSecOps Agentic AI Pipeline_






# ============================================================
# JOB 3: REMEDIATION SUGGESTIONS (ALWAYS RUNS)
# ============================================================
  remediation-suggestions:
      name: ðŸ’¡ Remediation Suggestions
      runs-on: ubuntu-latest
      needs: llm-agent-analysis
      if: always()
    
      outputs:
        suggestions_created: ${{ steps.generate.outputs.suggestions_created }}
    
      permissions:
        contents: write
        pull-requests: write
    
      steps:
        - uses: actions/checkout@v4
          with:
            fetch-depth: 0


            
        - name: Setup Python & Venv
          run: |
            sudo apt update && sudo apt install -y python3-venv
            python3 -m venv envmine
            # This makes 'pip' and 'python' use the venv automatically for this job
            echo "$GITHUB_WORKSPACE/envmine/bin" >> $GITHUB_PATH

        - name: Install Dependencies
          run: |
            # Now this uses the venv pip automatically!
            pip install -r requirements.txt


    
        - uses: actions/setup-python@v5
          with:
            python-version: ${{ env.PYTHON_VERSION }}
    
        - name: Install Python dependencies
          run: pip install pyyaml requests jq
    
        - uses: actions/download-artifact@v4
          with:
            name: scan-reports
            path: reports/
    
        - uses: actions/download-artifact@v4
          with:
            name: ai-results
            path: agent_output/
    
        - name: Start Ollama
          run: |
            set -e
            curl -fsSL https://ollama.com/install.sh | sh
            nohup ollama serve > /tmp/ollama.log 2>&1 &
            for i in $(seq 1 30); do
              curl -sf http://localhost:11434/api/tags > /dev/null 2>&1 && break
              sleep 2
            done
            ollama pull "$OLLAMA_MODEL"
    
        - name: Generate remediation or improvement suggestions
          id: generate
          env:
            OLLAMA_URL: "http://localhost:11434"
            PIPELINE_STATUS: ${{ needs.llm-agent-analysis.outputs.pipeline_status }}
          run: |
            set -e
            mkdir -p remediation-suggestions
    
            python3 << 'PYEOF'
            import json, os, sys, requests
            from pathlib import Path
            from datetime import datetime
    
            SUGGESTIONS = Path("remediation-suggestions")
            OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
            OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5-coder:7b")
            PIPELINE_STATUS = os.getenv("PIPELINE_STATUS", "unknown")
    
            def llm_ask(system_prompt: str, user_prompt: str) -> str:
                try:
                    resp = requests.post(
                        f"{OLLAMA_URL}/api/chat",
                        json={
                            "model": OLLAMA_MODEL,
                            "messages": [
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": user_prompt},
                            ],
                            "stream": False,
                            "options": {"temperature": 0.2, "num_predict": 1024},
                        },
                        timeout=120,
                    )
                    resp.raise_for_status()
                    return resp.json().get("message", {}).get("content", "")
                except Exception as e:
                print(f"[LLM Error] {e}")
                return ""
    
            summary = {
                "generated_at": datetime.utcnow().isoformat() + "Z",
                "pipeline_status": PIPELINE_STATUS,
                "mode": "improvement" if PIPELINE_STATUS != "fail" else "remediation",
            }
    
            readme = []
            readme.append("# ðŸ”§ Security Suggestions\n")
            readme.append(f"Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\n")
            readme.append(f"Pipeline status: **{PIPELINE_STATUS}**\n")
            readme.append("---\n")
    
            # =====================================================
            # MODE 1: PIPELINE PASSED â†’ IMPROVEMENT ONLY
            # =====================================================
            if PIPELINE_STATUS != "fail":
                print("[INFO] Pipeline passed â€” generating improvement suggestions.")
    
            improvement_prompt = """
                Repository passed all security gates.
                Provide a concise improvement and hardening checklist.
                
                Include:
                1. CI/CD hardening
                2. Dependency hygiene
                3. Secrets management
                4. Runtime security
                5. Monitoring and alerting
                """
    
                improvement = llm_ask(
                    "You are a senior DevSecOps architect.",
                    improvement_prompt,
                )
    
                (SUGGESTIONS / "security_improvements.md").write_text(
                    improvement if improvement.strip()
                    else "No improvement suggestions generated."
                )
    
                readme.append("## ðŸŸ¢ Security Improvements\n")
                readme.append("ðŸ“„ security_improvements.md\n")
                readme.append("Pipeline passed. These are improvement suggestions only.\n")
    
                (SUGGESTIONS / "remediation_summary.json").write_text(
                    json.dumps(summary, indent=2)
                )
    
                (SUGGESTIONS / "README.md").write_text("\n".join(readme))
    
                with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                    f.write("suggestions_created=true\n")
    
                sys.exit(0)
    
            # =====================================================
            # MODE 2: PIPELINE FAILED â†’ FULL REMEDIATION
            # =====================================================
            print("[INFO] Pipeline failed â€” generating remediation suggestions.")
    
            remediation_prompt = """
              Security scans detected critical or high vulnerabilities.
              
              Provide:
              1. Top priority fixes
              2. Ordered remediation steps
              3. Any configuration changes needed
              """
    
            remediation = llm_ask(
                "You are a senior security engineer.",
                remediation_prompt,
            )
    
            (SUGGESTIONS / "priority_remediation.md").write_text(
                remediation if remediation.strip()
                else "No remediation suggestions generated."
            )
    
            readme.append("## ðŸ”´ Remediation Required\n")
            readme.append("ðŸ“„ priority_remediation.md\n")
    
            (SUGGESTIONS / "remediation_summary.json").write_text(
                json.dumps(summary, indent=2)
            )
    
            (SUGGESTIONS / "README.md").write_text("\n".join(readme))
    
            with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                f.write("suggestions_created=true\n")
            PYEOF
    
        - name: Upload suggestion artifacts
          uses: actions/upload-artifact@v4
          with:
            name: remediation-suggestions
            path: remediation-suggestions/
    
        - name: Generate unique branch name
          id: branch
          run: |
            BRANCH="remediation/suggestions-run-${{ github.run_number }}"
            echo "name=$BRANCH" >> "$GITHUB_OUTPUT"
    
        - name: Create suggestions PR (only if pipeline failed)
          if: >
            steps.generate.outputs.suggestions_created == 'true' &&
            needs.llm-agent-analysis.outputs.pipeline_status == 'fail'
          uses: peter-evans/create-pull-request@v6
          with:
            token: ${{ secrets.GITHUB_TOKEN }}
            branch: ${{ steps.branch.outputs.name }}
            base: test-v-branch
            delete-branch: true
            add-paths: remediation-suggestions/**
            title: "ðŸ’¡ Security Remediation Suggestions (Run #${{ github.run_number }})"
            commit-message: "docs: add LLM-generated remediation suggestions"
            body: |
              AI-generated remediation suggestions.
              Review before applying.
    
    
    
    
    
    
    
    
    
    
    
    
    
    


# ============================================================
  # JOB 4: GATE (runs AFTER suggestions â€” final verdict)
  # ============================================================
  gate-check:
    name: ðŸš¦ Security Gate
    runs-on: ubuntu-latest
    needs: [llm-agent-analysis, remediation-suggestions]
    if: always()

    steps:
      - name: Download AI results
        uses: actions/download-artifact@v4
        with:
          name: ai-results
          path: agent_output/

      - name: Evaluate gate
        run: |
          if [ ! -f agent_output/decision.json ]; then
            echo "âŒ decision.json not found â€” failing gate"
            exit 1
          fi
          STATUS=$(jq -r '.status' agent_output/decision.json)
          echo "Final status: $STATUS"
          if [ "$STATUS" = "fail" ]; then
            echo "âŒ Security gate FAILED â€” review remediation suggestions in the PR"
            exit 1
          fi
          echo "âœ… Security gate PASSED"

  # ============================================================
  # JOB 5: Gmail Email Notification
  # ============================================================
  email-notification:
    name: ðŸ“§ Gmail Notification
    runs-on: ubuntu-latest
    needs: [llm-agent-analysis, remediation-suggestions, gate-check]
    if: always()

    steps:
      - name: ðŸ“§ Prepare & Send Email
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.GMAIL_USERNAME }}
          password: ${{ secrets.GMAIL_APP_PASSWORD }}
          subject: "${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'ðŸ”´ [SECURITY ALERT]' || 'ðŸŸ¢ [SECURITY OK]' }} ${{ github.repository }} - ${{ github.ref_name }}"
          to: ${{ secrets.NOTIFICATION_EMAIL }}
          from: "Agentic Pipeline DevSecOps Pipeline Vinayak<${{ secrets.GMAIL_USERNAME }}>"
          body: |
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        DevSecOps Security Scan Report
            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
            Status:     ${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'âŒ FAILED' || 'âœ… PASSED' }}
            Repository: ${{ github.repository }}
            Branch:     ${{ github.ref_name }}
            Commit:     ${{ github.sha }}
            Actor:      ${{ github.actor }}
            
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                SCAN RESULTS
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            Total Findings: ${{ needs.llm-agent-analysis.outputs.total_findings }}
            
            ðŸ”´ Critical:    ${{ needs.llm-agent-analysis.outputs.critical_count }}
            ðŸŸ  High:        ${{ needs.llm-agent-analysis.outputs.high_count }}
            ðŸŸ¡ Medium:      ${{ needs.llm-agent-analysis.outputs.medium_count }}
            
            Reason: ${{ needs.llm-agent-analysis.outputs.reason }}
            
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                            REMEDIATION SUGGESTIONS
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            Suggestions Generated: ${{ needs.remediation-suggestions.outputs.suggestions_created || 'N/A' }}
            Gate Result:           ${{ needs.gate-check.result }}
            
            ${{ needs.remediation-suggestions.outputs.suggestions_created == 'true' && 'ðŸ’¡ A PR with remediation suggestions has been created. Review and apply the fixes.' || '' }}
            
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                    LINKS
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            ðŸ“‹ View Run:    https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
            ðŸ“ View Commit: https://github.com/${{ github.repository }}/commit/${{ github.sha }}
            
            ${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'âš ï¸  ACTION REQUIRED: Please review remediation suggestions and fix security issues before merging.' || 'âœ… All security checks passed.' }}
            
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            DevSecOps Agentic AI Pipeline | Automated Security Scanning
          priority: ${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'high' || 'normal' }}













































# ###########################test
# name: DevSecOps Agentic AI Pipeline

# on:
#   push:
#     branches: [main, test-v-branch]
#   pull_request:
#     branches: [main, test-v-branch]
#   workflow_dispatch:

# env:
#   PYTHON_VERSION: "3.12"
#   APP_DIR: "Order-app-main"
#   REPORTS_DIR: "reports"
#   OUTPUT_DIR: "agent_output"
#   ACTIONS_STEP_DEBUG: "true"  
#   LLM_ENABLED: ${{ secrets.LLM_ENABLED }}
#   LLM_AUTOFIX: ${{ secrets.LLM_AUTOFIX }}   
#   OLLAMA_MODEL: ${{ secrets.OLLAMA_MODEL }}
#   OLLAMA_NUM_CTX: ${{ secrets.OLLAMA_NUM_CTX }}
#   OLLAMA_NUM_PREDICT: ${{ secrets.OLLAMA_NUM_PREDICT }}
#   OLLAMA_TEMPERATURE: ${{ secrets.OLLAMA_TEMPERATURE }}
#   MIN_SEVERITY: ${{ secrets.MIN_SEVERITY }}
#   LLM_AUTOFIX_TOOLS: ${{ secrets.LLM_AUTOFIX_TOOLS }}
  


# jobs:
# # ============================================================
# # JOB 1: SECURITY SCANS
# # ============================================================
#   security-scan:
#     name: ðŸ” Security Scan
#     runs-on: self-hosted

#     steps:
#       - uses: actions/checkout@v4
      
#       # THIS STEP must be repeated in every job
#       - name: Setup Python & Venv
#         run: |
#           sudo apt update && sudo apt install -y python3-venv
#           python3 -m venv envmine
#           # This makes 'pip' and 'python' use the venv automatically for this job
#           echo "$GITHUB_WORKSPACE/envmine/bin" >> $GITHUB_PATH

#       - name: Install Dependencies
#         run: |
#           # Now this uses the venv pip automatically!
#           pip install -r requirements.txt

    
      
#      ## ---------------- SEMGREP (CODE) ----------------
#       - name: Run Semgrep (Application)
#         run: |
#           set -e
#           pip install semgrep
#           semgrep scan \
#             --config=auto \
#             --json \
#             --output $REPORTS_DIR/semgrep.json \
#             $APP_DIR
#           test -f $REPORTS_DIR/semgrep.json
      
#       - name: Run Trivy FS (Application)
#         run: |
#           set -e
      
#           curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh
#           sudo mv ./bin/trivy /usr/local/bin/trivy
      
#           trivy version
      
#           trivy fs \
#             --format json \
#             --output $REPORTS_DIR/trivy_fs.json \
#             $APP_DIR
      
#           test -f $REPORTS_DIR/trivy_fs.json


#       # ---------------- TRIVY IMAGE () ----------------
#       - name: Run Trivy Image (if Dockerfile exists)
#         run: |
#           set -e
#           if [ -f "$APP_DIR/Dockerfile" ]; then
#             docker build -t order-app:scan $APP_DIR
#             trivy image \
#               --format json \
#               --output $REPORTS_DIR/trivy_image.json \
#               order-app:scan
#           else
#             echo '{}' > $REPORTS_DIR/trivy_image.json
#           fi
#           test -f $REPORTS_DIR/trivy_image.json


#       # ---------------- TFSEC ----------------
#       - name: Install tfsec
#         run: |
#           set -e
#           curl -sfL https://raw.githubusercontent.com/aquasecurity/tfsec/master/scripts/install_linux.sh | bash

#       - name: Run tfsec
#         run: |
#           set -e
#           tfsec terraform --format json \
#             > "$REPORTS_DIR/tfsec.json" || true
#           test -f "$REPORTS_DIR/tfsec.json"

#       # ---------------- GITLEAKS ----------------
#       - name: Install Gitleaks
#         run: |
#           set -e
#           sudo apt-get update
#           sudo apt-get install -y jq
#           VERSION=$(curl -s https://api.github.com/repos/gitleaks/gitleaks/releases/latest | jq -r .tag_name)
#           curl -sL https://github.com/gitleaks/gitleaks/releases/download/${VERSION}/gitleaks_${VERSION#v}_linux_x64.tar.gz \
#             | tar -xz
#           sudo mv gitleaks /usr/local/bin/

#       - name: Run Gitleaks
#         run: |
#           set -e
#           gitleaks detect --source . --report-format json \
#             --report-path "$REPORTS_DIR/gitleaks.json" --no-git || true
#           test -f "$REPORTS_DIR/gitleaks.json"

#       # ---------------- CONFTEST (POLICY) ----------------
#       - name: Install Conftest
#         run: |
#           set -e
#           sudo apt-get update
#           sudo apt-get install -y jq curl
      
#           VERSION=$(curl -s https://api.github.com/repos/open-policy-agent/conftest/releases/latest | jq -r .tag_name)
#           echo "Installing conftest $VERSION"
      
#           curl -sL https://github.com/open-policy-agent/conftest/releases/download/${VERSION}/conftest_${VERSION#v}_Linux_x86_64.tar.gz \
#             | tar -xz
      
#           sudo mv conftest /usr/local/bin/
#           conftest --version

#       - name: Run Conftest (Policies)
#         run: |
#             set -e
#             conftest test k8s terraform policy \
#               --output json \
#               > "$REPORTS_DIR/conftest.json" || echo "[]" > "$REPORTS_DIR/conftest.json"
        
#             test -f "$REPORTS_DIR/conftest.json"
          


#       - name: Upload scan reports
#         uses: actions/upload-artifact@v4
#         with:
#           name: scan-reports
#           path: reports/




# # ============================================================
# # JOB 2: AI ANALYSIS (OLLAMA ENABLED)
# # ============================================================
#   llm-agent-analysis:
#     name: ðŸ¤– Agentic AI Analysis
#     runs-on: self-hosted
#     needs: security-scan

#     outputs:
#       pipeline_status: ${{ steps.status.outputs.pipeline_status }}

#     steps:
#       - uses: actions/checkout@v4
#       - uses: actions/setup-python@v5
#         with:
#           python-version: ${{ env.PYTHON_VERSION }}

#       - name: Setup Python & Venv
#         run: |
#           sudo apt update && sudo apt install -y python3-venv
#           python3 -m venv envmine
#           # This makes 'pip' and 'python' use the venv automatically for this job
#           echo "$GITHUB_WORKSPACE/envmine/bin" >> $GITHUB_PATH

#       - name: Install Dependencies
#         run: |
#           # Now this uses the venv pip automatically!
#           pip install -r requirements.txt

#       - run: pip install pyyaml requests jq

#       - uses: actions/download-artifact@v4
#         with:
#           name: scan-reports
#           path: reports/

#       # ---------- START OLLAMA ----------
#       - name: Start Ollama
#         run: |
#           set -e
#           curl -fsSL https://ollama.com/install.sh | sh
#           nohup ollama serve > /tmp/ollama.log 2>&1 &
#           sleep 10
#           ollama pull "$OLLAMA_MODEL"

#       - name: Run agentic analysis
#         run: |
#           python main.py --verbose || true

#       - name: Capture decision
#         id: status
#         run: |
#           STATUS=$(jq -r '.status' "$OUTPUT_DIR/decision.json")
#           echo "pipeline_status=$STATUS" >> "$GITHUB_OUTPUT"

#       - uses: actions/upload-artifact@v4
#         with:
#           name: ai-results
#           path: agent_output/
          
# # # ============================================================
# #   # JOB 3: REMEDIATION SUGGESTIONS (LLM generates fix files)
# #   #
# #   # OUTPUT STRUCTURE (in remediation-suggestions/ folder):
# #   #   remediation-suggestions/
# #   #   â”œâ”€â”€ README.md                        â† overview + how to apply
# #   #   â”œâ”€â”€ semgrep_suggestions.py           â† Python/app code fixes
# #   #   â”œâ”€â”€ trivy_fs_suggestions.md          â† filesystem vulnerability fixes
# #   #   â”œâ”€â”€ trivy_image_suggestions.md       â† container image fixes
# #   #   â”œâ”€â”€ tfsec_suggestions.tf             â† copy-paste Terraform fixes
# #   #   â”œâ”€â”€ gitleaks_suggestions.md          â† secrets remediation steps
# #   #   â”œâ”€â”€ conftest_suggestions.yaml        â† policy-compliant K8s/TF snippets
# #   #   â”œâ”€â”€ llm_analysis_recommendations.md  â† full LLM analysis from Job 2
# #   #   â””â”€â”€ remediation_summary.json         â† machine-readable summary
# #   #
# #   # NO SOURCE CODE IS MODIFIED.
# #   # ============================================================
# #   remediation-suggestions:
# #     name: ðŸ’¡ Remediation Suggestions
# #     runs-on: ubuntu-latest
# #     needs: llm-agent-analysis
# #     if: >-
# #       always() &&
# #       github.event_name == 'push' &&
# #       needs.llm-agent-analysis.outputs.pipeline_status == 'fail'

# #     outputs:
# #       suggestions_created: ${{ steps.generate.outputs.suggestions_created }}

# #     permissions:
# #       contents: write
# #       pull-requests: write

# #     steps:
# #       - uses: actions/checkout@v4
# #         with:
# #           fetch-depth: 0

# #       - uses: actions/setup-python@v5
# #         with:
# #           python-version: ${{ env.PYTHON_VERSION }}

# #       - name: Install Python dependencies
# #         run: pip install pyyaml requests jq

# #       - uses: actions/download-artifact@v4
# #         with:
# #           name: scan-reports
# #           path: reports/

# #       - uses: actions/download-artifact@v4
# #         with:
# #           name: ai-results
# #           path: agent_output/

# #       - name: Start Ollama
# #         run: |
# #           set -e
# #           curl -fsSL https://ollama.com/install.sh | sh
# #           nohup ollama serve > /tmp/ollama.log 2>&1 &
# #           for i in $(seq 1 30); do
# #             curl -sf http://localhost:11434/api/tags > /dev/null 2>&1 && break
# #             sleep 2
# #           done
# #           ollama pull "$OLLAMA_MODEL"

# #       - name: Generate remediation suggestions
# #         id: generate
# #         env:
# #           OLLAMA_URL: "http://localhost:11434"
# #         run: |
# #           set -e
# #           mkdir -p remediation-suggestions

# #           python3 << 'PYEOF'
# #           import json, os, sys, requests, yaml
# #           from pathlib import Path
# #           from datetime import datetime

# #           REPORTS = Path("reports")
# #           SUGGESTIONS = Path("remediation-suggestions")
# #           AGENT_OUTPUT = Path("agent_output")
# #           OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
# #           OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5-coder:7b")

# #           def llm_ask(system_prompt: str, user_prompt: str) -> str:
# #               """Ask Ollama for a suggestion. Returns empty string on failure."""
# #               try:
# #                   resp = requests.post(
# #                       f"{OLLAMA_URL}/api/chat",
# #                       json={
# #                           "model": OLLAMA_MODEL,
# #                           "messages": [
# #                               {"role": "system", "content": system_prompt},
# #                               {"role": "user", "content": user_prompt},
# #                           ],
# #                           "stream": False,
# #                           "options": {
# #                               "temperature": 0.2,
# #                               "num_predict": int(os.getenv("OLLAMA_NUM_PREDICT", "2048")),
# #                           },
# #                       },
# #                       timeout=120,
# #                   )
# #                   resp.raise_for_status()
# #                   return resp.json().get("message", {}).get("content", "")
# #               except Exception as e:
# #                   print(f"[LLM Error] {e}")
# #                   return ""

# #           def load_json(path: Path) -> dict | list:
# #               try:
# #                   return json.loads(path.read_text())
# #               except Exception:
# #                   return {}

# #           summary = {
# #               "generated_at": datetime.utcnow().isoformat() + "Z",
# #               "tools": {},
# #               "total_findings": 0,
# #               "total_suggestions": 0,
# #           }

# #           readme_sections = []
# #           readme_sections.append("# ðŸ”§ Remediation Suggestions\n")
# #           readme_sections.append(f"Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\n")
# #           readme_sections.append("These are **LLM-generated suggestions** for review. ")
# #           readme_sections.append("**No source code was modified.** Review each suggestion ")
# #           readme_sections.append("carefully before applying.\n")
# #           readme_sections.append("---\n")

# #           # ==============================================================
# #           # SEMGREP (Application code â€” Python, JS, etc.)
# #           # Report: reports/semgrep.json
# #           # ==============================================================
# #           semgrep_data = load_json(REPORTS / "semgrep.json")
# #           semgrep_results = semgrep_data.get("results", []) if isinstance(semgrep_data, dict) else []

# #           if semgrep_results:
# #               print(f"[semgrep] Processing {len(semgrep_results)} finding(s)...")
# #               sg_suggestions = []
# #               sg_suggestions.append("# ==================================================")
# #               sg_suggestions.append("# SEMGREP REMEDIATION SUGGESTIONS")
# #               sg_suggestions.append("# Generated by DevSecOps Agentic AI Pipeline")
# #               sg_suggestions.append("# Review carefully before applying to your source files")
# #               sg_suggestions.append("# ==================================================\n")

# #               for i, finding in enumerate(semgrep_results, 1):
# #                   check_id = finding.get("check_id", "")
# #                   severity = finding.get("extra", {}).get("severity", "UNKNOWN")
# #                   message = finding.get("extra", {}).get("message", "")
# #                   filepath = finding.get("path", "unknown")
# #                   start_line = finding.get("start", {}).get("line", "?")
# #                   end_line = finding.get("end", {}).get("line", "?")
# #                   # Try to get the matched code snippet
# #                   snippet = finding.get("extra", {}).get("lines", "")
# #                   if not snippet:
# #                       snippet = finding.get("extra", {}).get("matched_code", "")

# #                   prompt = (
# #                       f"Semgrep finding:\n"
# #                       f"- Rule: {check_id}\n"
# #                       f"- Severity: {severity}\n"
# #                       f"- File: {filepath} (lines {start_line}-{end_line})\n"
# #                       f"- Message: {message}\n"
# #                       f"- Vulnerable code:\n```\n{snippet}\n```\n\n"
# #                       f"Tasks:\n"
# #                       f"1. Explain the vulnerability in 1-2 lines\n"
# #                       f"2. Generate the CORRECTED code that fixes this issue\n"
# #                       f"3. Show exactly which file and line numbers to replace\n"
# #                       f"4. Note any imports or dependencies needed\n\n"
# #                       f"Output the corrected code in a code block with the language specified."
# #                   )

# #                   suggestion = llm_ask(
# #                       "You are a senior application security engineer. Generate safe, minimal "
# #                       "code fixes. Always show the corrected code block with the target file "
# #                       "and line numbers. Never introduce new vulnerabilities.",
# #                       prompt,
# #                   )

# #                   sg_suggestions.append(f"# --- Finding {i}: {check_id} [{severity}] ---")
# #                   sg_suggestions.append(f"# File: {filepath} (lines {start_line}-{end_line})")
# #                   sg_suggestions.append(f"# Issue: {message[:200]}")
# #                   sg_suggestions.append(f"# Vulnerable code:")
# #                   for line in str(snippet).splitlines():
# #                       sg_suggestions.append(f"#   {line}")
# #                   sg_suggestions.append(f"#")
# #                   sg_suggestions.append(f"# --- Suggested fix ---")
# #                   if suggestion.strip():
# #                       sg_suggestions.append(suggestion.strip())
# #                   else:
# #                       sg_suggestions.append("# [LLM could not generate a suggestion for this finding]")
# #                   sg_suggestions.append("\n")

# #               (SUGGESTIONS / "semgrep_suggestions.py").write_text("\n".join(sg_suggestions))
# #               summary["tools"]["semgrep"] = {"findings": len(semgrep_results), "suggestions": len(semgrep_results)}
# #               summary["total_findings"] += len(semgrep_results)
# #               summary["total_suggestions"] += len(semgrep_results)

# #               readme_sections.append(f"## ðŸ Application Code (Semgrep) â€” {len(semgrep_results)} finding(s)\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/semgrep_suggestions.py`\n")
# #               readme_sections.append("**How to apply:** Review each finding, copy the corrected code ")
# #               readme_sections.append("into the indicated file at the specified line numbers.\n")
# #           else:
# #               print("[semgrep] No findings or report not found.")

# #           # ==============================================================
# #           # TRIVY FS (Filesystem â€” misconfigs, vulnerabilities in code)
# #           # Report: reports/trivy_fs.json
# #           # ==============================================================
# #           trivy_fs_data = load_json(REPORTS / "trivy_fs.json")
# #           trivy_fs_results = []
# #           if isinstance(trivy_fs_data, dict):
# #               for result in trivy_fs_data.get("Results", []):
# #                   target = result.get("Target", "")
# #                   # Misconfigurations
# #                   for misconf in result.get("Misconfigurations", []):
# #                       trivy_fs_results.append({
# #                           "type": "misconfiguration",
# #                           "target": target,
# #                           "id": misconf.get("ID", ""),
# #                           "title": misconf.get("Title", ""),
# #                           "description": misconf.get("Description", ""),
# #                           "severity": misconf.get("Severity", "UNKNOWN"),
# #                           "resolution": misconf.get("Resolution", ""),
# #                           "primary_url": misconf.get("PrimaryURL", ""),
# #                       })
# #                   # Vulnerabilities
# #                   for vuln in result.get("Vulnerabilities", []):
# #                       trivy_fs_results.append({
# #                           "type": "vulnerability",
# #                           "target": target,
# #                           "id": vuln.get("VulnerabilityID", ""),
# #                           "pkg_name": vuln.get("PkgName", ""),
# #                           "installed": vuln.get("InstalledVersion", ""),
# #                           "fixed": vuln.get("FixedVersion", ""),
# #                           "severity": vuln.get("Severity", "UNKNOWN"),
# #                           "title": vuln.get("Title", ""),
# #                           "description": vuln.get("Description", ""),
# #                           "primary_url": vuln.get("PrimaryURL", ""),
# #                       })

# #           if trivy_fs_results:
# #               print(f"[trivy_fs] Processing {len(trivy_fs_results)} finding(s)...")
# #               tfs_suggestions = []
# #               tfs_suggestions.append("# ðŸ” Trivy Filesystem Remediation Suggestions\n")
# #               tfs_suggestions.append("Generated by DevSecOps Agentic AI Pipeline.\n")
# #               tfs_suggestions.append("---\n")

# #               for i, finding in enumerate(trivy_fs_results, 1):
# #                   if finding["type"] == "misconfiguration":
# #                       prompt = (
# #                           f"Trivy filesystem misconfiguration:\n"
# #                           f"- ID: {finding['id']}\n"
# #                           f"- Severity: {finding['severity']}\n"
# #                           f"- File: {finding['target']}\n"
# #                           f"- Title: {finding['title']}\n"
# #                           f"- Description: {finding['description'][:300]}\n"
# #                           f"- Recommended resolution: {finding['resolution']}\n\n"
# #                           f"Provide the corrected configuration code that fixes this misconfiguration. "
# #                           f"Show the exact file and what to change."
# #                       )
# #                   else:
# #                       prompt = (
# #                           f"Trivy filesystem vulnerability:\n"
# #                           f"- CVE: {finding['id']}\n"
# #                           f"- Severity: {finding['severity']}\n"
# #                           f"- Package: {finding.get('pkg_name', '')} "
# #                           f"(installed: {finding.get('installed', '')}, "
# #                           f"fixed: {finding.get('fixed', 'N/A')})\n"
# #                           f"- File: {finding['target']}\n"
# #                           f"- Title: {finding.get('title', '')}\n\n"
# #                           f"Provide step-by-step remediation:\n"
# #                           f"1. How to update the vulnerable package\n"
# #                           f"2. The exact command or file change needed\n"
# #                           f"3. Any breaking changes to watch for"
# #                       )

# #                   suggestion = llm_ask(
# #                       "You are a cloud security engineer specializing in infrastructure "
# #                       "and dependency security. Provide safe, actionable remediation steps.",
# #                       prompt,
# #                   )

# #                   tfs_suggestions.append(f"## Finding {i}: `{finding['id']}` [{finding['severity']}]\n")
# #                   tfs_suggestions.append(f"**File:** `{finding['target']}`\n")
# #                   if finding["type"] == "misconfiguration":
# #                       tfs_suggestions.append(f"**Title:** {finding['title']}\n")
# #                   else:
# #                       tfs_suggestions.append(f"**Package:** {finding.get('pkg_name', '')} "
# #                                               f"({finding.get('installed', '')} â†’ {finding.get('fixed', 'N/A')})\n")
# #                   if suggestion.strip():
# #                       tfs_suggestions.append(suggestion.strip())
# #                   else:
# #                       tfs_suggestions.append("*LLM could not generate a suggestion.*")
# #                   tfs_suggestions.append("\n---\n")

# #               (SUGGESTIONS / "trivy_fs_suggestions.md").write_text("\n".join(tfs_suggestions))
# #               summary["tools"]["trivy_fs"] = {"findings": len(trivy_fs_results), "suggestions": len(trivy_fs_results)}
# #               summary["total_findings"] += len(trivy_fs_results)
# #               summary["total_suggestions"] += len(trivy_fs_results)

# #               readme_sections.append(f"## ðŸ” Filesystem Scan (Trivy FS) â€” {len(trivy_fs_results)} finding(s)\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/trivy_fs_suggestions.md`\n")
# #               readme_sections.append("**How to apply:** Follow the remediation steps for each finding. ")
# #               readme_sections.append("Update packages or fix misconfigurations as indicated.\n")
# #           else:
# #               print("[trivy_fs] No findings or report not found.")

# #           # ==============================================================
# #           # TRIVY IMAGE (Container image vulnerabilities)
# #           # Report: reports/trivy_image.json
# #           # ==============================================================
# #           trivy_img_data = load_json(REPORTS / "trivy_image.json")
# #           trivy_img_results = []
# #           if isinstance(trivy_img_data, dict):
# #               for result in trivy_img_data.get("Results", []):
# #                   target = result.get("Target", "")
# #                   for vuln in result.get("Vulnerabilities", []):
# #                       trivy_img_results.append({
# #                           "target": target,
# #                           "id": vuln.get("VulnerabilityID", ""),
# #                           "pkg_name": vuln.get("PkgName", ""),
# #                           "installed": vuln.get("InstalledVersion", ""),
# #                           "fixed": vuln.get("FixedVersion", ""),
# #                           "severity": vuln.get("Severity", "UNKNOWN"),
# #                           "title": vuln.get("Title", ""),
# #                       })

# #           if trivy_img_results:
# #               print(f"[trivy_image] Processing {len(trivy_img_results)} finding(s)...")
# #               ti_suggestions = []
# #               ti_suggestions.append("# ðŸ³ Trivy Image Remediation Suggestions\n")
# #               ti_suggestions.append("These findings are from scanning the container image.\n")
# #               ti_suggestions.append("---\n")

# #               for i, finding in enumerate(trivy_img_results, 1):
# #                   prompt = (
# #                       f"Container image vulnerability:\n"
# #                       f"- CVE: {finding['id']}\n"
# #                       f"- Severity: {finding['severity']}\n"
# #                       f"- Image layer: {finding['target']}\n"
# #                       f"- Package: {finding['pkg_name']} "
# #                       f"(installed: {finding['installed']}, fixed: {finding['fixed'] or 'N/A'})\n"
# #                       f"- Title: {finding.get('title', '')}\n\n"
# #                       f"Provide remediation:\n"
# #                       f"1. Dockerfile changes needed (e.g., base image update, package pin)\n"
# #                       f"2. The exact Dockerfile line to modify\n"
# #                       f"3. Any multi-stage build optimizations"
# #                   )

# #                   suggestion = llm_ask(
# #                       "You are a container security expert. Provide Dockerfile fixes "
# #                       "that resolve vulnerabilities while keeping images minimal and secure.",
# #                       prompt,
# #                   )

# #                   ti_suggestions.append(f"## Finding {i}: `{finding['id']}` [{finding['severity']}]\n")
# #                   ti_suggestions.append(f"**Image layer:** `{finding['target']}`\n")
# #                   ti_suggestions.append(f"**Package:** {finding['pkg_name']} "
# #                                          f"({finding['installed']} â†’ {finding['fixed'] or 'N/A'})\n")
# #                   if suggestion.strip():
# #                       ti_suggestions.append(suggestion.strip())
# #                   else:
# #                       ti_suggestions.append("*LLM could not generate a suggestion.*")
# #                   ti_suggestions.append("\n---\n")

# #               (SUGGESTIONS / "trivy_image_suggestions.md").write_text("\n".join(ti_suggestions))
# #               summary["tools"]["trivy_image"] = {"findings": len(trivy_img_results), "suggestions": len(trivy_img_results)}
# #               summary["total_findings"] += len(trivy_img_results)
# #               summary["total_suggestions"] += len(trivy_img_results)

# #               readme_sections.append(f"## ðŸ³ Container Image (Trivy Image) â€” {len(trivy_img_results)} finding(s)\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/trivy_image_suggestions.md`\n")
# #               readme_sections.append("**How to apply:** Update your Dockerfile with the suggested base image ")
# #               readme_sections.append("or package version changes.\n")
# #           else:
# #               print("[trivy_image] No findings or report not found.")

# #           # ==============================================================
# #           # TFSEC (Terraform security)
# #           # Report: reports/tfsec.json
# #           # ==============================================================
# #           tfsec_data = load_json(REPORTS / "tfsec.json")
# #           tfsec_results = tfsec_data.get("results", []) if isinstance(tfsec_data, dict) else []

# #           if tfsec_results:
# #               print(f"[tfsec] Processing {len(tfsec_results)} finding(s)...")
# #               tf_suggestions = []
# #               tf_suggestions.append("# ==============================================")
# #               tf_suggestions.append("# TFSEC REMEDIATION SUGGESTIONS")
# #               tf_suggestions.append("# Generated by DevSecOps Agentic AI Pipeline")
# #               tf_suggestions.append("# Review carefully before applying to your .tf files")
# #               tf_suggestions.append("# ==============================================\n")

# #               for i, finding in enumerate(tfsec_results, 1):
# #                   severity = finding.get("severity", "UNKNOWN")
# #                   rule_id = finding.get("rule_id", finding.get("long_id", ""))
# #                   desc = finding.get("description", "")
# #                   filename = finding.get("location", {}).get("filename", "unknown")
# #                   start_line = finding.get("location", {}).get("start_line", "?")
# #                   end_line = finding.get("location", {}).get("end_line", "?")

# #                   prompt = (
# #                       f"tfsec finding:\n"
# #                       f"- Rule: {rule_id}\n"
# #                       f"- Severity: {severity}\n"
# #                       f"- File: {filename} (lines {start_line}-{end_line})\n"
# #                       f"- Description: {desc}\n\n"
# #                       f"Generate the corrected Terraform code block that fixes this issue. "
# #                       f"Output ONLY the corrected HCL code wrapped in a Terraform code block. "
# #                       f"Add a comment showing which file and line to apply it to."
# #                   )

# #                   suggestion = llm_ask(
# #                       "You are a Terraform security expert. Generate safe, minimal Terraform fixes. "
# #                       "Output only HCL code blocks with comments indicating the target file and line.",
# #                       prompt,
# #                   )

# #                   tf_suggestions.append(f"# --- Finding {i}: {rule_id} [{severity}] ---")
# #                   tf_suggestions.append(f"# File: {filename} (lines {start_line}-{end_line})")
# #                   tf_suggestions.append(f"# Issue: {desc}")
# #                   if suggestion.strip():
# #                       tf_suggestions.append(suggestion.strip())
# #                   else:
# #                       tf_suggestions.append(f"# [LLM could not generate a suggestion for this finding]")
# #                   tf_suggestions.append("")

# #               (SUGGESTIONS / "tfsec_suggestions.tf").write_text("\n".join(tf_suggestions))
# #               summary["tools"]["tfsec"] = {"findings": len(tfsec_results), "suggestions": len(tfsec_results)}
# #               summary["total_findings"] += len(tfsec_results)
# #               summary["total_suggestions"] += len(tfsec_results)

# #               readme_sections.append(f"## ðŸ—ï¸ Terraform (tfsec) â€” {len(tfsec_results)} finding(s)\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/tfsec_suggestions.tf`\n")
# #               readme_sections.append("**How to apply:** Copy the corrected code blocks into your `.tf` files ")
# #               readme_sections.append("at the indicated file and line numbers.\n")
# #           else:
# #               print("[tfsec] No findings.")

# #           # ==============================================================
# #           # GITLEAKS (Secrets detection)
# #           # Report: reports/gitleaks.json
# #           # ==============================================================
# #           gitleaks_data = load_json(REPORTS / "gitleaks.json")
# #           gitleaks_results = gitleaks_data if isinstance(gitleaks_data, list) else []

# #           if gitleaks_results:
# #               print(f"[gitleaks] Processing {len(gitleaks_results)} finding(s)...")
# #               gl_suggestions = []
# #               gl_suggestions.append("# ðŸ”‘ Gitleaks Remediation Suggestions\n")
# #               gl_suggestions.append("These findings indicate potential secrets in your codebase.\n")
# #               gl_suggestions.append("---\n")

# #               for i, finding in enumerate(gitleaks_results, 1):
# #                   rule = finding.get("RuleID", finding.get("rule", ""))
# #                   match_val = finding.get("Match", finding.get("match", ""))[:40] + "..."
# #                   filename = finding.get("File", finding.get("file", ""))
# #                   line = finding.get("StartLine", finding.get("line", "?"))

# #                   prompt = (
# #                       f"Gitleaks finding:\n"
# #                       f"- Rule: {rule}\n"
# #                       f"- File: {filename} (line {line})\n"
# #                       f"- Match preview: {match_val}\n\n"
# #                       f"Provide step-by-step remediation:\n"
# #                       f"1. How to remove/rotate the secret\n"
# #                       f"2. How to prevent re-commit (e.g., .gitignore, env vars)\n"
# #                       f"3. Git history cleanup command if needed"
# #                   )

# #                   suggestion = llm_ask(
# #                       "You are a secrets management expert. Provide clear, actionable steps. "
# #                       "Never include the actual secret in your response.",
# #                       prompt,
# #                   )

# #                   gl_suggestions.append(f"## Finding {i}: `{rule}` in `{filename}:{line}`\n")
# #                   if suggestion.strip():
# #                       gl_suggestions.append(suggestion.strip())
# #                   else:
# #                       gl_suggestions.append("*LLM could not generate a suggestion.*")
# #                   gl_suggestions.append("\n---\n")

# #               (SUGGESTIONS / "gitleaks_suggestions.md").write_text("\n".join(gl_suggestions))
# #               summary["tools"]["gitleaks"] = {"findings": len(gitleaks_results), "suggestions": len(gitleaks_results)}
# #               summary["total_findings"] += len(gitleaks_results)
# #               summary["total_suggestions"] += len(gitleaks_results)

# #               readme_sections.append(f"## ðŸ”‘ Secrets (Gitleaks) â€” {len(gitleaks_results)} finding(s)\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/gitleaks_suggestions.md`\n")
# #               readme_sections.append("**How to apply:** Follow the step-by-step instructions to rotate ")
# #               readme_sections.append("secrets and clean git history.\n")
# #           else:
# #               print("[gitleaks] No findings.")

# #           # ==============================================================
# #           # CONFTEST (Policy violations)
# #           # Report: reports/conftest.json
# #           # ==============================================================
# #           conftest_data = load_json(REPORTS / "conftest.json")
# #           conftest_failures = []
# #           if isinstance(conftest_data, list):
# #               for entry in conftest_data:
# #                   if isinstance(entry, dict):
# #                       for f in entry.get("failures", []):
# #                           conftest_failures.append({
# #                               "file": entry.get("filename", ""),
# #                               "msg": f.get("msg", "") if isinstance(f, dict) else str(f),
# #                           })

# #           if conftest_failures:
# #               print(f"[conftest] Processing {len(conftest_failures)} failure(s)...")
# #               ct_suggestions = []

# #               for i, failure in enumerate(conftest_failures, 1):
# #                   filename = failure.get("file", "unknown")
# #                   msg = failure.get("msg", "")

# #                   prompt = (
# #                       f"Conftest policy failure:\n"
# #                       f"- File: {filename}\n"
# #                       f"- Policy violation: {msg}\n\n"
# #                       f"Generate the corrected YAML or HCL snippet that satisfies this policy. "
# #                       f"Output ONLY the corrected code with a comment showing the target file."
# #                   )

# #                   suggestion = llm_ask(
# #                       "You are a Kubernetes/Terraform policy expert. Generate minimal, "
# #                       "policy-compliant code fixes. Output corrected YAML or HCL only.",
# #                       prompt,
# #                   )

# #                   ct_suggestions.append(f"# --- Policy Failure {i} ---")
# #                   ct_suggestions.append(f"# File: {filename}")
# #                   ct_suggestions.append(f"# Violation: {msg}")
# #                   if suggestion.strip():
# #                       ct_suggestions.append(suggestion.strip())
# #                   else:
# #                       ct_suggestions.append("# [LLM could not generate a suggestion]")
# #                   ct_suggestions.append("")

# #               (SUGGESTIONS / "conftest_suggestions.yaml").write_text("\n".join(ct_suggestions))
# #               summary["tools"]["conftest"] = {"findings": len(conftest_failures), "suggestions": len(conftest_failures)}
# #               summary["total_findings"] += len(conftest_failures)
# #               summary["total_suggestions"] += len(conftest_failures)

# #               readme_sections.append(f"## ðŸ“‹ Policy (Conftest) â€” {len(conftest_failures)} failure(s)\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/conftest_suggestions.yaml`\n")
# #               readme_sections.append("**How to apply:** Copy the corrected YAML/HCL into the target files.\n")
# #           else:
# #               print("[conftest] No failures.")

# #           # ==============================================================
# #           # INCLUDE LLM RECOMMENDATIONS FROM AI ANALYSIS (Job 2)
# #           # ==============================================================
# #           llm_reco = AGENT_OUTPUT / "llm_recommendations.md"
# #           if llm_reco.exists():
# #               content = llm_reco.read_text()
# #               (SUGGESTIONS / "llm_analysis_recommendations.md").write_text(content)
# #               readme_sections.append("## ðŸ¤– LLM Analysis Recommendations\n")
# #               readme_sections.append(f"ðŸ“„ **File:** `remediation-suggestions/llm_analysis_recommendations.md`\n")
# #               readme_sections.append("Full LLM analysis from the AI pipeline.\n")

# #           # ---- WRITE SUMMARY JSON ----
# #           (SUGGESTIONS / "remediation_summary.json").write_text(
# #               json.dumps(summary, indent=2)
# #           )

# #           # ---- WRITE README ----
# #           if summary["total_findings"] == 0:
# #               readme_sections.append("## âœ… No actionable findings\n")
# #               readme_sections.append("All scans passed or produced no parseable findings.\n")

# #           readme_sections.append("---\n")
# #           readme_sections.append("## How to use this PR\n")
# #           readme_sections.append("1. **Review** each suggestion file in `remediation-suggestions/`\n")
# #           readme_sections.append("2. **Copy-paste** the corrected code into your source files\n")
# #           readme_sections.append("3. **Test** your changes locally\n")
# #           readme_sections.append("4. **Commit** to your branch\n")
# #           readme_sections.append("5. **Close** this PR once all suggestions are applied or dismissed\n")
# #           readme_sections.append("\n> âš ï¸ These are AI-generated suggestions. Always review before applying.\n")

# #           (SUGGESTIONS / "README.md").write_text("\n".join(readme_sections))

# #           has_suggestions = summary["total_suggestions"] > 0
# #           print(f"\nâœ… Generated {summary['total_suggestions']} suggestion(s) across {len(summary['tools'])} tool(s)")

# #           with open(os.environ["GITHUB_OUTPUT"], "a") as f:
# #               f.write(f"suggestions_created={'true' if has_suggestions else 'false'}\n")

# #           PYEOF

# #       - name: Show generated suggestions
# #         run: |
# #           echo "=== Suggestion files ==="
# #           ls -la remediation-suggestions/ || echo "No files"
# #           echo ""
# #           echo "=== README.md ==="
# #           cat remediation-suggestions/README.md 2>/dev/null || echo "Not found"
# #           echo ""
# #           echo "=== Summary ==="
# #           cat remediation-suggestions/remediation_summary.json 2>/dev/null || echo "Not found"

# #       - name: Upload suggestion artifacts
# #         uses: actions/upload-artifact@v4
# #         with:
# #           name: remediation-suggestions
# #           path: remediation-suggestions/

# #       - name: Generate unique branch name
# #         id: branch
# #         run: |
# #           BRANCH="remediation/suggestions-run-${{ github.run_number }}"
# #           echo "name=$BRANCH" >> "$GITHUB_OUTPUT"

# #       - name: Create suggestions PR
# #         if: steps.generate.outputs.suggestions_created == 'true'
# #         uses: peter-evans/create-pull-request@v6
# #         with:
# #           token: ${{ secrets.GITHUB_TOKEN }}
# #           branch: ${{ steps.branch.outputs.name }}
# #           base: test-v-branch
# #           delete-branch: true
# #           add-paths: remediation-suggestions/**
# #           title: "ðŸ’¡ Security Remediation Suggestions (Run #${{ github.run_number }})"
# #           commit-message: "docs: add LLM-generated remediation suggestions"
# #           body: |
# #             ## ðŸ’¡ AI-Generated Remediation Suggestions

# #             **Run:** #${{ github.run_number }}
# #             **Trigger:** Security scan found issues that need attention.

# #             ### ðŸ“ What's in this PR

# #             This PR contains **suggestion files only** â€” no source code was modified.

# #             | Folder | Contents |
# #             |--------|----------|
# #             | `remediation-suggestions/` | Per-tool fix suggestions you can copy-paste |

# #             ### ðŸ“‹ How to use

# #             1. Review each file in `remediation-suggestions/`
# #             2. Copy the corrected code into your source files
# #             3. Test locally
# #             4. Commit your changes
# #             5. Close this PR

# #             > âš ï¸ **These are AI-generated suggestions. Always review before applying.**

# #             ---
# #             _Generated by DevSecOps Agentic AI Pipeline_






# # ============================================================
# # JOB 3: REMEDIATION SUGGESTIONS (ALWAYS RUNS)
# # ============================================================
#   remediation-suggestions:
#       name: ðŸ’¡ Remediation Suggestions
#       runs-on: self-hosted
#       needs: llm-agent-analysis
#       if: always()
    
#       outputs:
#         suggestions_created: ${{ steps.generate.outputs.suggestions_created }}
    
#       permissions:
#         contents: write
#         pull-requests: write
    
#       steps:
#         - uses: actions/checkout@v4
#           with:
#             fetch-depth: 0


            
#         - name: Setup Python & Venv
#           run: |
#             sudo apt update && sudo apt install -y python3-venv
#             python3 -m venv envmine
#             # This makes 'pip' and 'python' use the venv automatically for this job
#             echo "$GITHUB_WORKSPACE/envmine/bin" >> $GITHUB_PATH

#         - name: Install Dependencies
#           run: |
#             # Now this uses the venv pip automatically!
#             pip install -r requirements.txt


    
#         - uses: actions/setup-python@v5
#           with:
#             python-version: ${{ env.PYTHON_VERSION }}
    
#         - name: Install Python dependencies
#           run: pip install pyyaml requests jq
    
#         - uses: actions/download-artifact@v4
#           with:
#             name: scan-reports
#             path: reports/
    
#         - uses: actions/download-artifact@v4
#           with:
#             name: ai-results
#             path: agent_output/
    
#         - name: Start Ollama
#           run: |
#             set -e
#             curl -fsSL https://ollama.com/install.sh | sh
#             nohup ollama serve > /tmp/ollama.log 2>&1 &
#             for i in $(seq 1 30); do
#               curl -sf http://localhost:11434/api/tags > /dev/null 2>&1 && break
#               sleep 2
#             done
#             ollama pull "$OLLAMA_MODEL"
    
#         - name: Generate remediation or improvement suggestions
#           id: generate
#           env:
#             OLLAMA_URL: "http://localhost:11434"
#             PIPELINE_STATUS: ${{ needs.llm-agent-analysis.outputs.pipeline_status }}
#           run: |
#             set -e
#             mkdir -p remediation-suggestions
    
#             python3 << 'PYEOF'
#             import json, os, sys, requests
#             from pathlib import Path
#             from datetime import datetime
    
#             SUGGESTIONS = Path("remediation-suggestions")
#             OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
#             OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5-coder:7b")
#             PIPELINE_STATUS = os.getenv("PIPELINE_STATUS", "unknown")
    
#             def llm_ask(system_prompt: str, user_prompt: str) -> str:
#                 try:
#                     resp = requests.post(
#                         f"{OLLAMA_URL}/api/chat",
#                         json={
#                             "model": OLLAMA_MODEL,
#                             "messages": [
#                                 {"role": "system", "content": system_prompt},
#                                 {"role": "user", "content": user_prompt},
#                             ],
#                             "stream": False,
#                             "options": {"temperature": 0.2, "num_predict": 1024},
#                         },
#                         timeout=120,
#                     )
#                     resp.raise_for_status()
#                     return resp.json().get("message", {}).get("content", "")
#                 except Exception as e:
#                 print(f"[LLM Error] {e}")
#                 return ""
    
#             summary = {
#                 "generated_at": datetime.utcnow().isoformat() + "Z",
#                 "pipeline_status": PIPELINE_STATUS,
#                 "mode": "improvement" if PIPELINE_STATUS != "fail" else "remediation",
#             }
    
#             readme = []
#             readme.append("# ðŸ”§ Security Suggestions\n")
#             readme.append(f"Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\n")
#             readme.append(f"Pipeline status: **{PIPELINE_STATUS}**\n")
#             readme.append("---\n")
    
#             # =====================================================
#             # MODE 1: PIPELINE PASSED â†’ IMPROVEMENT ONLY
#             # =====================================================
#             if PIPELINE_STATUS != "fail":
#                 print("[INFO] Pipeline passed â€” generating improvement suggestions.")
    
#             improvement_prompt = """
#                 Repository passed all security gates.
#                 Provide a concise improvement and hardening checklist.
                
#                 Include:
#                 1. CI/CD hardening
#                 2. Dependency hygiene
#                 3. Secrets management
#                 4. Runtime security
#                 5. Monitoring and alerting
#                 """
    
#                 improvement = llm_ask(
#                     "You are a senior DevSecOps architect.",
#                     improvement_prompt,
#                 )
    
#                 (SUGGESTIONS / "security_improvements.md").write_text(
#                     improvement if improvement.strip()
#                     else "No improvement suggestions generated."
#                 )
    
#                 readme.append("## ðŸŸ¢ Security Improvements\n")
#                 readme.append("ðŸ“„ security_improvements.md\n")
#                 readme.append("Pipeline passed. These are improvement suggestions only.\n")
    
#                 (SUGGESTIONS / "remediation_summary.json").write_text(
#                     json.dumps(summary, indent=2)
#                 )
    
#                 (SUGGESTIONS / "README.md").write_text("\n".join(readme))
    
#                 with open(os.environ["GITHUB_OUTPUT"], "a") as f:
#                     f.write("suggestions_created=true\n")
    
#                 sys.exit(0)
    
#             # =====================================================
#             # MODE 2: PIPELINE FAILED â†’ FULL REMEDIATION
#             # =====================================================
#             print("[INFO] Pipeline failed â€” generating remediation suggestions.")
    
#             remediation_prompt = """
#               Security scans detected critical or high vulnerabilities.
              
#               Provide:
#               1. Top priority fixes
#               2. Ordered remediation steps
#               3. Any configuration changes needed
#               """
    
#             remediation = llm_ask(
#                 "You are a senior security engineer.",
#                 remediation_prompt,
#             )
    
#             (SUGGESTIONS / "priority_remediation.md").write_text(
#                 remediation if remediation.strip()
#                 else "No remediation suggestions generated."
#             )
    
#             readme.append("## ðŸ”´ Remediation Required\n")
#             readme.append("ðŸ“„ priority_remediation.md\n")
    
#             (SUGGESTIONS / "remediation_summary.json").write_text(
#                 json.dumps(summary, indent=2)
#             )
    
#             (SUGGESTIONS / "README.md").write_text("\n".join(readme))
    
#             with open(os.environ["GITHUB_OUTPUT"], "a") as f:
#                 f.write("suggestions_created=true\n")
#             PYEOF
    
#         - name: Upload suggestion artifacts
#           uses: actions/upload-artifact@v4
#           with:
#             name: remediation-suggestions
#             path: remediation-suggestions/
    
#         - name: Generate unique branch name
#           id: branch
#           run: |
#             BRANCH="remediation/suggestions-run-${{ github.run_number }}"
#             echo "name=$BRANCH" >> "$GITHUB_OUTPUT"
    
#         - name: Create suggestions PR (only if pipeline failed)
#           if: >
#             steps.generate.outputs.suggestions_created == 'true' &&
#             needs.llm-agent-analysis.outputs.pipeline_status == 'fail'
#           uses: peter-evans/create-pull-request@v6
#           with:
#             token: ${{ secrets.GITHUB_TOKEN }}
#             branch: ${{ steps.branch.outputs.name }}
#             base: test-v-branch
#             delete-branch: true
#             add-paths: remediation-suggestions/**
#             title: "ðŸ’¡ Security Remediation Suggestions (Run #${{ github.run_number }})"
#             commit-message: "docs: add LLM-generated remediation suggestions"
#             body: |
#               AI-generated remediation suggestions.
#               Review before applying.
    
    
    
    
    
    
    
    
    
    
    
    
    
    


# # ============================================================
#   # JOB 4: GATE (runs AFTER suggestions â€” final verdict)
#   # ============================================================
#   gate-check:
#     name: ðŸš¦ Security Gate
#     runs-on: self-hosted
#     needs: [llm-agent-analysis, remediation-suggestions]
#     if: always()

#     steps:
#       - name: Download AI results
#         uses: actions/download-artifact@v4
#         with:
#           name: ai-results
#           path: agent_output/

#       - name: Evaluate gate
#         run: |
#           if [ ! -f agent_output/decision.json ]; then
#             echo "âŒ decision.json not found â€” failing gate"
#             exit 1
#           fi
#           STATUS=$(jq -r '.status' agent_output/decision.json)
#           echo "Final status: $STATUS"
#           if [ "$STATUS" = "fail" ]; then
#             echo "âŒ Security gate FAILED â€” review remediation suggestions in the PR"
#             exit 1
#           fi
#           echo "âœ… Security gate PASSED"

#   # ============================================================
#   # JOB 5: Gmail Email Notification
#   # ============================================================
#   email-notification:
#     name: ðŸ“§ Gmail Notification
#     runs-on: self-hosted
#     needs: [llm-agent-analysis, remediation-suggestions, gate-check]
#     if: always()

#     steps:
#       - name: ðŸ“§ Prepare & Send Email
#         uses: dawidd6/action-send-mail@v3
#         with:
#           server_address: smtp.gmail.com
#           server_port: 587
#           username: ${{ secrets.GMAIL_USERNAME }}
#           password: ${{ secrets.GMAIL_APP_PASSWORD }}
#           subject: "${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'ðŸ”´ [SECURITY ALERT]' || 'ðŸŸ¢ [SECURITY OK]' }} ${{ github.repository }} - ${{ github.ref_name }}"
#           to: ${{ secrets.NOTIFICATION_EMAIL }}
#           from: "Agentic Pipeline DevSecOps Pipeline Vinayak<${{ secrets.GMAIL_USERNAME }}>"
#           body: |
#             â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                         DevSecOps Security Scan Report
#             â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
#             Status:     ${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'âŒ FAILED' || 'âœ… PASSED' }}
#             Repository: ${{ github.repository }}
#             Branch:     ${{ github.ref_name }}
#             Commit:     ${{ github.sha }}
#             Actor:      ${{ github.actor }}
            
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#                                 SCAN RESULTS
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
#             Total Findings: ${{ needs.llm-agent-analysis.outputs.total_findings }}
            
#             ðŸ”´ Critical:    ${{ needs.llm-agent-analysis.outputs.critical_count }}
#             ðŸŸ  High:        ${{ needs.llm-agent-analysis.outputs.high_count }}
#             ðŸŸ¡ Medium:      ${{ needs.llm-agent-analysis.outputs.medium_count }}
            
#             Reason: ${{ needs.llm-agent-analysis.outputs.reason }}
            
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#                             REMEDIATION SUGGESTIONS
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
#             Suggestions Generated: ${{ needs.remediation-suggestions.outputs.suggestions_created || 'N/A' }}
#             Gate Result:           ${{ needs.gate-check.result }}
            
#             ${{ needs.remediation-suggestions.outputs.suggestions_created == 'true' && 'ðŸ’¡ A PR with remediation suggestions has been created. Review and apply the fixes.' || '' }}
            
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#                                     LINKS
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
#             ðŸ“‹ View Run:    https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
#             ðŸ“ View Commit: https://github.com/${{ github.repository }}/commit/${{ github.sha }}
            
#             ${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'âš ï¸  ACTION REQUIRED: Please review remediation suggestions and fix security issues before merging.' || 'âœ… All security checks passed.' }}
            
#             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#             DevSecOps Agentic AI Pipeline | Automated Security Scanning
#           priority: ${{ needs.llm-agent-analysis.outputs.pipeline_status == 'fail' && 'high' || 'normal' }}
